{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural Convolucional - Classificação Multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, datasets, utils, preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obter os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A base de dados já está dividida em dois conjuntos: treino e teste\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60000 imagens para treino\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10000 imagens para teste\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3d1c3a1128>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Número zero a preto e branco\n",
    "plt.imshow(X_train[1], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz com os pixeis da imagem com o número zero\n",
    "# Matriz 28x28\n",
    "pixeis = X_train[1]\n",
    "pixeis.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60000 imagens para treino\n",
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformar os dados num vector em que o tensorflow consiga fazer a sua leitura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1º parametro: número de imagens\n",
    "# 2º parametro: Altura da imagem (nº de pixeis da imagem na vertical).\n",
    "# 3º parametro: Largura da imagem (nº de pixeis da imagem na horizontal).\n",
    "\n",
    "# Nº de canais de RGB: Como a cor não tem influência neste caso pode-se utilizar a imagem a preto e branco(rgb=1). Quando se \n",
    "# utilizam as imagens a cores (rgb=3) o algoritmo fica mais lento porque aumenta a dimensionalidade dos dados. Uma imagem a \n",
    "# cores tem 3 canais(valores) dentro de cada pixel, porque o pixel é subdividio em vermelho(r), verde(g e azul(b)). Com rgb=1 \n",
    "# tem-se menos dados para processar.\n",
    "\n",
    "# A escala de cinzento possui apenas um canal. Quanto mais próximo de 255 mais claro é o cinzento e quanto mais próximo de \n",
    "# 0 mais escura é a cor.\n",
    "# Nesta escala o Pixel com o valor 255 é o branco e pixel 0 é o preto. Ao redor do número tem-se apenas o valor 0, que indica o \n",
    "# preto(o fundo é preto).\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão dos dados do tipo int8 para float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como os dados vão ser convertidos para uma escala entre 0 e 1 tem-se de converter os dados de inteiro8 para float32 para que\n",
    "# os valores obtidos depois da normalização não sejam inteiros e consequentemente quase todos 0(por não haver números decimais).\n",
    "\n",
    "X_test[0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão dos dados em float 32\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos pixeis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passar os pixeis para uma escala de 0 a 1 para que o precessamento dos dados seja mais rapido\n",
    "# Isto pode ser feito através da tecnica min max normalization. Como cada pixel ocupa 1 byte e o byte consegue guardar 256\n",
    "# resultados possiveis(ou seja varia entre 0 e 255). \n",
    "# A normalização pode ser feita dividindo o pixel por 255 (tambem se podia utilizar o skit-learn).\n",
    "\n",
    "# Pode-se ver que o valor máximo de um pixel é de 255\n",
    "X_test[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização do conjunto de teste e treino\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação de variaveis em dummys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como se trata de um problema de multiplas classes, cada classe tem de ter a probabilidade de pertencer a um número, ou seja\n",
    "# tem de ser um vector [60000,10] e [10000,10] (exigencia da biblioteca) e não se pode utilizar o LabelEncoder.\n",
    "\n",
    "# número 1: 1 0 0 0 0 0 0 0 0 0\n",
    "# número 2: 0 1 0 0 0 0 0 0 0 0\n",
    "# ....\n",
    "# número 0: 0 0 0 0 0 0 0 0 0 1\n",
    "\n",
    "# tambem se podia utilizar o pd.get_dummies()\n",
    "y_train = utils.to_categorical(y_train, 10)\n",
    "y_test = utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN de 1 camada de convolução e 1 camada oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential - uma cada apos a outra\n",
    "# dense - camadas fully conected, cada neuronio esta conectado a todos os neuronios da camada seguinte\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de convolução (conv2D porque é uma imagem):\n",
    "\n",
    "# Operador de convolução: multiplicação da imagem(matriz de pixeis 28x28) por um detector de caracteristicas, feature detection\n",
    "# ou filtro ou kernel(matriz normalmente 3x3 para imagens pequenas) que vai originar um mapa de caracteristicas.\n",
    "# Este mapa tem como objectivo filtrar(detectar) as caracteristicas mais importantes da imagem. \n",
    "\n",
    "# Detectores de caracteristicas:32, Utilizam-se 32 matrizes de detectores de caraceristicas que vão originar 32 mapas de\n",
    "# caracteristicas. Estes detectores de caracteristicas são originados variando os números da matriz até se obter aquele que \n",
    "# apresenta o melhor resultado. O recomendado é utilizar 64 kernels e seus multiplos(128, 256, 512, 1024, etc).\n",
    "\n",
    "# Kernel_size: (3,3) matriz detectora de caracteristicas do tamanho 3x3 \n",
    "\n",
    "# strider: (1,1) Os valores do mapa de caracteristicas são obtidos com a subdivisão da matriz da imagem a fazer-se movendo um \n",
    "# pixel para a direita e um pixel para baixo.\n",
    "\n",
    "# input_shape: dimensões da imagem e número de canais(1 para imagens sem cor e 3 para imagens com cor)\n",
    "\n",
    "# função de activação: Aplica a função relu(transforma valores negativos em zero e mantem os restantes iguais) ao mapa de \n",
    "# caracteristicas. Isto permite detectar melhor os padrões(Transforma os pontos mais escuros(com valores negativos) em pontos \n",
    "# mais claros e mais parecidos com os restantes pontos).\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de Pooling\n",
    "# O mapa de caracteristicas(neste caso 5x5) é percorrido por uma matriz(neste caso 2x2) para encontrar os valores maiores\n",
    "#(caracteristicas mais importantes) e formar um nova matriz com esses valores(Poolin matrix).  \n",
    "# Os valores da matriz de pooling são obtidos com a subdivisão do mapa de caracteristicas a fazer-se movendo uma coluna para a\n",
    "# direita e uma coluna para baixo.\n",
    "# Como neste caso tem-se 32 mapas de caracteristicas tem-se igual número de matrizes de pooling.\n",
    "\n",
    "# Utiliza-se o Max Pooling para se obter o maior valor e assim realçar as caracteristicas principais da imagem. (tambem se podia\n",
    "# utilizar a média ou o minimo valor).\n",
    "\n",
    "# pool_size: (2,2) tamanho da matriz utilizada para seleccionar as carateristicas do mapa de caracteristicas. Vai originar uma\n",
    "# matriz pooling.\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada de Flattening\n",
    "\n",
    "# Transformar a matriz de pooling num vector que irá ser utilizado na camada de entrada da rede neural densa.\n",
    "# Os valores dos neuronios da camada de entrada da rede neural serão os valores desse vector.\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1ª camada oculta\n",
    "# número de neuronios para primeira modelação:\n",
    "# (28x28)=784 multiplicada pelo kernel(3x3) origina uma matriz de caracteristicas (26,26) e originar uma matriz de pooling \n",
    "# (13x13) e o respectivo array com 169 valores. Ou seja irá-se ter em média 169 valores de entrada.\n",
    "# ((169+10)/2=90). Optou-se por colocar 128 neuronios.\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de Saida\n",
    "# Neuronios: Igual ao número de saidas possiveis, neste caso são 10 classes.\n",
    "# Função de activação: softmax é a função utilizada para problemas de classificação multiclasse. Para se obter a probabilidade\n",
    "# para cada uma das classes (por ex. para um neurónio tem-se a probabilidade de 10% de ser num 1, 80% num 7 e 10% de ser num 5).\n",
    "# A classe atribuida será aquela que tem maior probabilidade.\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), input_shape=(28, 28, 1), activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(layers.Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilação e Ajuste do modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer: adam é uma optimização da descida do gradiente estócastico (usado para encontrar os melhores valores dos pesos).\n",
    "# É o que melhor se adapta à maioria dos casos.\n",
    "\n",
    "# loss = função de perda categorical_crossentropy é a mais utilizada para classificação multiclasse.\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0702 20:51:44.091973  3832 deprecation.py:323] From C:\\Users\\Bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 31s 523us/sample - loss: 0.2439 - accuracy: 0.9301 - val_loss: 0.0877 - val_accuracy: 0.9743\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 32s 530us/sample - loss: 0.0736 - accuracy: 0.9788 - val_loss: 0.0577 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x8822d097f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size: 150, calcula-se o erro de um conjunto de 150 dados e actualizam-se todos os pesos (O detector de caracteristicas\n",
    "# só é actualizado(mudado) no fim de cada época).\n",
    "\n",
    "# epochs: Quantas vezes o algoritmo percorre o conjunto de dados de treino totalmente e escolhe-se um detector de \n",
    "# carateristicas melhor. \n",
    "\n",
    "# 1ª epoca- calcula o erro para os primeiros 150 dados e actualiza todos os pesos. Calcula o o erro para os 150 dados seguintes \n",
    "# e actualiza todos os pesos. E assim sucessivamente. Actualiza-se(muda-se) o detector de caracteristica no fim de cada época.\n",
    "# 2ª epoca- calcula o erro para os primeiros 150 dados(com os pesos da 1ª epoca) e actualiza todos os pesos. Calcula o o erro \n",
    "# para os 150 dados seguintes(com os pesos da 1ª epoca) e actualiza todos os pesos. E assim sucessivamente. Actualiza-se\n",
    "# (muda-se) o detector de caracteristica no fim de cada época.\n",
    "# 6000/150 = 40 batchs. Os pesos e o detector de caracteristicas são actualizados 40 vezes em cada epoca.\n",
    "\n",
    "# Validation data: Avaliação do modelo utilizando a base de dados de teste (val_accuracy).\n",
    "\n",
    "# Ajustar os dados de entrada de treino aos dados de saida de treino para treinar o modelo\n",
    "model.fit(X_train, y_train, batch_size=150, epochs=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão e Avaliação do Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9957687e-01, 1.5177308e-06, 9.2517257e-05, 3.0233089e-06,\n",
       "       2.7084630e-05, 1.7202319e-05, 2.0452947e-04, 4.8592148e-05,\n",
       "       2.5223162e-06, 2.6379515e-05], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prever os dados de teste para avaliar o modelo\n",
    "predictions = model.predict(X_test)\n",
    "predictions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de modo a se poder utilizar a matriz de confusão e o relatorio de classificação para avaliar o modelo tem-se de transformar \n",
    "# o vectores prediction e y_teste do formato [10000,10] para [10000,1] (exigencia da biblioteca sklearn).\n",
    "\n",
    "# Retorna o número do indice que tem a probabilidade mais alta(que neste caso é igual ao número na figura).\n",
    "predictions_index = [np.argmax(index) for index in np.array(predictions)]\n",
    "predictions_index[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retorna o número do indice que tem a probabilidade mais alta(que neste caso é igual ao número na figura).\n",
    "y_test_index = [np.argmax(index) for index in np.array(y_test)]\n",
    "y_test_index[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction index</th>\n",
       "      <th>teste index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction index  teste index\n",
       "0                 7            7\n",
       "1                 2            2\n",
       "2                 1            1\n",
       "3                 0            0\n",
       "4                 4            4"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparação entre os números obtidos usando o X_test(predicion) e y_test(reais).\n",
    "pd.DataFrame({\"prediction index\": predictions_index, \"teste index\":y_test_index}).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       1.00      1.00      1.00      1135\n",
      "           2       1.00      1.00      1.00      1032\n",
      "           3       1.00      1.00      1.00      1010\n",
      "           4       1.00      1.00      1.00       982\n",
      "           5       1.00      1.00      1.00       892\n",
      "           6       1.00      1.00      1.00       958\n",
      "           7       1.00      1.00      1.00      1028\n",
      "           8       1.00      1.00      1.00       974\n",
      "           9       1.00      1.00      1.00      1009\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Relatório de classificação\n",
    "#Ver como o modelo se ajusta para os dados de teste\n",
    "print(classification_report(y_test_index, predictions_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test_index,predictions_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>Predicted</th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\"></th>\n",
       "      <th>0</th>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\"></th>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Predicted                           \n",
       "            0     1     2     3         4    5    6     7    8     9\n",
       "       0  980     0     0     0         0    0    0     0    0     0\n",
       "       1    0  1135     0     0         0    0    0     0    0     0\n",
       "       2    0     0  1032     0         0    0    0     0    0     0\n",
       "       3    0     0     0  1010         0    0    0     0    0     0\n",
       "Actual 4    0     0     0     0       982    0    0     0    0     0\n",
       "       5    0     0     0     0         0  892    0     0    0     0\n",
       "       6    0     0     0     0         0    0  958     0    0     0\n",
       "       7    0     0     0     0         0    0    0  1028    0     0\n",
       "       8    0     0     0     0         0    0    0     0  974     0\n",
       "       9    0     0     0     0         0    0    0     0    0  1009"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matriz de confusão\n",
    "outside_columns = [\"\",\"\",\"\",\"\",\"Predicted\",\"\",\"\",\"\",\"\",\"\"]\n",
    "outside_index = [\"\",\"\",\"\",\"\",\"Actual\",\"\",\"\",\"\",\"\",\"\"]\n",
    "inside = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "\n",
    "hier_columns = list(zip(outside_columns, inside))\n",
    "hier_columns = pd.MultiIndex.from_tuples(hier_columns)\n",
    "\n",
    "hier_index = list(zip(outside_index, inside))\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)\n",
    "\n",
    "pd.DataFrame(confusion, columns=hier_columns, index = hier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 198us/sample - loss: 0.0592 - accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05921043620593846, 0.9808]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Com o TensorFlow 2.0 pode-se avaliar o modelo de forma mais expedita através do método evaluate. \n",
    "# Sem ser necessário criar o relatorio de classificação e as respectivas transformações na variavel de saida (transformar o \n",
    "# array de [10000,3] para [10000,1].\n",
    "# Os métodos de avaliação podem ser definidos quando se cria o modelo (neste caso escolheu-se apenas a accuracy).\n",
    "# Esta avaliação tambem foi feita no ajuste do modelo ao defenir-se o validation_data.\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsão de uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1º parâmetro: Altura da imagem (nº de pixeis da imagem na vertical).\n",
    "# 2º parâmetro: Largura da imagem (nº de pixeis da imagem na horizontal).\n",
    "# 3º parâmetro: Escala rgb: 1 para escala de cinzentos.\n",
    "\n",
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionar uma nova dimenção ao array com a imagem\n",
    "\n",
    "# 1º parâmetro: número de imagens\n",
    "# 2º parâmetro: Altura da imagem (nº de pixeis da imagem na vertical).\n",
    "# 3º parâmetro: Largura da imagem (nº de pixeis da imagem na horizontal).\n",
    "# 4º parâmetro: Escala rgb: 1 para escala de cinzentos.\n",
    "\n",
    "image = np.expand_dims(X_test[0],axis = 0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x8825b882b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualização do número da imagem\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previsão do número na imagem\n",
    "\n",
    "# Como é um problema de classificação multiclasse(utilizou-se a função softmax), considera-se que a imagem pertence à classe que\n",
    "# tem a probabilidade mais alta(pode-se utilizar o argmax, para saber o indice do array com o maior valor).\n",
    "result = model.predict(image)\n",
    "result.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN com 2 camadas de convolução e 2 camadas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential - uma cada apos a outra\n",
    "# dense - camadas fully conected, cada neuronio esta conectado a todos os neuronios da camada seguinte\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de convolução (conv2D porque é uma imagem):\n",
    "\n",
    "# Operador de convolução: multiplicação da imagem(matriz de pixeis 28x28) por um detector de caracteristicas, feature detection\n",
    "# ou filtro ou kernel(matriz normalmente 3x3 para imagens pequenas) que vai originar um mapa de caracteristicas.\n",
    "# Este mapa tem como objectivo filtrar(detectar) as caracteristicas mais importantes da imagem. \n",
    "\n",
    "# Detectores de caracteristicas:32, Utilizam-se 32 matrizes de detectores de caraceristicas que vão originar 32 mapas de\n",
    "# caracteristicas. Estes detectores de caracteristicas são originados variando os números da matriz até se obter aquele que \n",
    "# apresenta o melhor resultado. O recomendado é utilizar 64 kernels e seus multiplos(128, 256, 512, 1024, etc).\n",
    "\n",
    "# Kernel_size: (3,3) matriz detectora de caracteristicas do tamanho 3x3 \n",
    "\n",
    "# strider: (1,1) Os valores do mapa de caracteristicas são obtidos com a subdivisão da matriz da imagem a fazer-se movendo um \n",
    "# pixel para a direita e um pixel para baixo.\n",
    "\n",
    "# input_shape: dimensões da imagem e número de canais(1 para imagens sem cor e 3 para imagens com cor)\n",
    "\n",
    "# função de activação: Aplica a função relu(transforma valores negativos em zero e mantem os restantes iguais) ao mapa de \n",
    "# caracteristicas. Isto permite detectar melhor os padrões(Transforma os pontos mais escuros(com valores negativos) em pontos \n",
    "# mais claros e mais parecidos com os restantes pontos).\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada de Normalização\n",
    "# A normalização dos pixeis já foi feita anteriormente para a camada de entrada(com X_train/255 e X_test/255). Essa \n",
    "# normalização tambem pode ser feita para as camadas de convoluções, a normalização é feita no mapa de caracteristicas onde \n",
    "# todos os valores passam a estar entre 0 e 1. \n",
    "# Isto faz com que o processamento do algoritmo seja mais rapido.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de Pooling\n",
    "# O mapa de caracteristicas(neste caso 5x5) é percorrido por uma matriz(neste caso 2x2) para encontrar os valores maiores\n",
    "#(caracteristicas mais importantes) e formar um nova matriz com esses valores(Poolin matrix).  \n",
    "# Os valores da matriz de pooling são obtidos com a subdivisão do mapa de caracteristicas a fazer-se movendo uma coluna para a\n",
    "# direita e uma coluna para baixo.\n",
    "# Como neste caso tem-se 32 mapas de caracteristicas tem-se igual número de matrizes de pooling.\n",
    "\n",
    "# Utiliza-se o Max Pooling para se obter o maior valor e assim realçar as caracteristicas principais da imagem. (tambem se podia\n",
    "# utilizar a média ou o minimo valor).\n",
    "\n",
    "# pool_size: (2,2) tamanho da matriz utilizada para seleccionar as carateristicas do mapa de caracteristicas. Vai originar uma\n",
    "# matriz pooling.\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada de Flattening\n",
    "\n",
    "# Transformar a matriz de pooling num vector que irá ser utilizado na camada de entrada da rede neural densa.\n",
    "# Os valores dos neuronios da camada de entrada da rede neural serão os valores desse vector.\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1ª camada oculta\n",
    "# número de neuronios para primeira modelação:\n",
    "# (28x28)=784 multiplicada pelo kernel(3x3) origina uma matriz de caracteristicas (26,26) e originar uma matriz de pooling \n",
    "# (13x13) e o respectivo array com 169 valores. Ou seja irá-se ter em média 169 valores de entrada.\n",
    "# ((169+10)/2=90). Optou-se por colocar 128 neuronios.\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada Dropout\n",
    "# Ajuda a prevenir o overfitting(que em redes neurais convolucionais tem grande probabilidade de acontecer devido aos muitos\n",
    "# parametros que se utilizam).\n",
    "# Coloca-se zeros em alguns valores/neuronios da camada de entrada de forma aleatoria. Escolhe-se a quantidade/percentagem de \n",
    "# neuronios que terão valor zero. Ao se colocar o valor zero estes neuronios não teram influencia no modelo. Normalmente \n",
    "# utiliza-se uma percentagem entre 20% a 30%. Se for demasiado elevado(maior que 50%) o modelo pode entrar em underfitting, \n",
    "# porque não consegue aprender, pois tem demasiadas entradas que não são consideradas.\n",
    "# Como se utilizam menos variaveis é mais dificil haver alguma que não tenham sido treinada e que o modelo não consiga prever.\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de Saida\n",
    "# Neuronios: Igual ao número de saidas possiveis, neste caso são 10 classes.\n",
    "# Função de activação: softmax é a função utilizada para problemas de classificação multiclasse. Para se obter a probabilidade\n",
    "# para cada uma das classes (por ex. para um neurónio tem-se a probabilidade de 10% de ser num 1, 80% num 7 e 10% de ser num 5).\n",
    "# A classe atribuida será aquela que tem maior probabilidade.\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "# 1ª camada de convolução:\n",
    "# 1º: Multiplicação da imgem(input) pela detector de caracteristicas para obter o mapa de caracteristicas\n",
    "# 2º: Percorrer o mapa de caracteristicas com uma matriz para encontrar os valores maiores e formar a matriz de pooling.\n",
    "# 2ª camada de convolução:\n",
    "# 3º: Multiplicar a matriz de pooling pelo detector de caracteristicas para obter o mapa de caracteristicas mais refinado\n",
    "# 4º: Percorrer o mapa de caracteristicas com uma matriz para encontrar os valores maiores e formar a matriz de pooling mais\n",
    "# refinada\n",
    "\n",
    "# Camada de entrada da rede neural densa:\n",
    "# 5º: trasformar a matriz de pooling refinada num vector para servir de camada de entrada da rede neural densa\n",
    "# 1ª camada de oculta:\n",
    "# 6º: multiplicar os valores do vector pelos pesos para obter a função soma e aplicar a função relu a esse resultado para obter\n",
    "# o valor de cada neurónio da 1ª camada oculta\n",
    "# 2ª camada de oculta:\n",
    "# 7º: multiplicar os valores dos neuronios da 1ª camada oculta pelos pesos para obter a função soma e aplicar a função \n",
    "# relu a esse resultado para obter o valor de cada neurónio da 2ª camada oculta\n",
    "# camada de saida:\n",
    "# 8º: multiplicar os valores dos neuronios da 2ª camada oculta pelos pesos para obter a função soma de cada neuronio da camada\n",
    "# de saida. Aplicar a função softmax aos resultados da função para obter a probabilidade do neuronio pertencer à classe que se\n",
    "# definiu.\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), input_shape=(28, 28, 1), activation=\"relu\")) # 1ª camada de convolução e definição da camada\n",
    "model.add(layers.BatchNormalization())                                          # de entrada\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation=\"relu\")) # 2ª camada de convolução\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten()) # funciona como camada de entrada da rede neural oculta\n",
    "\n",
    "model.add(layers.Dense(units=128, activation=\"relu\")) # 1ª camada de oculta\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(units=128, activation=\"relu\")) # 2ª camada de oculta\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(units=10, activation=\"softmax\")) # camada de saida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilação e Ajuste do modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 11:09:29.080182   388 deprecation.py:323] From C:\\Users\\Bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 196s 3ms/sample - loss: 0.2086 - accuracy: 0.9356 - val_loss: 0.2325 - val_accuracy: 0.9329\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.0622 - accuracy: 0.9813 - val_loss: 0.0420 - val_accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x477983ce10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar os dados de entrada de treino aos dados de saida de treino para treinar o modelo\n",
    "model.fit(X_train, y_train, batch_size=150, epochs=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obter os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A base de dados está dividida em dois conjuntos: treino e teste\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar as variaveis de entrada da base de dados de treino e de teste\n",
    "X = np.vstack((X_train, X_test))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar as variaveis de saida da base de dados de treino e de teste\n",
    "y = np.hstack((y_train,y_test))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-Processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar os dados num vector em que o tensorflow consiga fazer a sua leitura.\n",
    "X = X.reshape(X.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão dos dados do tipo int8 para float32\n",
    "X = X.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização dos pixeis\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para a cross validation não se pode utilizar o pd.gotDummies() porque ocorre um erro por causa das dimensões do array.\n",
    "# Neste caso tem de se utilizar um array [70000,1] e não [70000,10] (exigencia da biblioteca sklearn).\n",
    "\n",
    "# Transformação de variaveis em dummys\n",
    "#y = utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza-se o KerasClassifier porque é um problema de classificação\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Criar o modelo de CNN numa função\n",
    "\n",
    "def model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), input_shape=(28, 28, 1), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(units=128, activation=\"relu\"))\n",
    "    model.add(layers.Dense(units=10, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=model, epochs=2, batch_size=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 12:43:41.125284  6472 deprecation.py:323] From C:\\Users\\Bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52500 samples\n",
      "Epoch 1/2\n",
      "52500/52500 [==============================] - 27s 513us/sample - loss: 0.2496 - categorical_accuracy: 0.9279\n",
      "Epoch 2/2\n",
      "52500/52500 [==============================] - 26s 498us/sample - loss: 0.0770 - categorical_accuracy: 0.9781\n",
      "Train on 52500 samples\n",
      "Epoch 1/2\n",
      "52500/52500 [==============================] - 27s 510us/sample - loss: 0.2388 - categorical_accuracy: 0.9330\n",
      "Epoch 2/2\n",
      "52500/52500 [==============================] - 26s 504us/sample - loss: 0.0747 - categorical_accuracy: 0.9781\n",
      "Train on 52500 samples\n",
      "Epoch 1/2\n",
      "52500/52500 [==============================] - 26s 487us/sample - loss: 0.2517 - categorical_accuracy: 0.9293\n",
      "Epoch 2/2\n",
      "52500/52500 [==============================] - 25s 469us/sample - loss: 0.0719 - categorical_accuracy: 0.9783\n",
      "Train on 52500 samples\n",
      "Epoch 1/2\n",
      "52500/52500 [==============================] - 26s 493us/sample - loss: 0.2627 - categorical_accuracy: 0.9241\n",
      "Epoch 2/2\n",
      "52500/52500 [==============================] - 26s 493us/sample - loss: 0.0766 - categorical_accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "\n",
    "scoring = ['precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "\n",
    "scores = cross_validate(estimator=model, X=X, y=y, cv=4, scoring=\"accuracy\", return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([56.34674001, 54.07681227, 51.43444228, 52.45727754]),\n",
       " 'score_time': array([3.34220004, 2.94535613, 2.36308646, 2.61775637]),\n",
       " 'test_score': array([0.97714286, 0.97931429, 0.97582857, 0.98211429])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores obtidos para a accuracy atraves de cross validation\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9786"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy média dos sub conjuntos de teste\n",
    "np.mean(scores[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002380361831524715"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desvio padrão obtido atraves dos valores da accuracy dos sub conjuntos de teste\n",
    "# quanto maior este valor maior é a probabilidade de existir overfitting (o modelo não generaliza bem e adapta-se demasiado bem\n",
    "# aos dados de treino, e quando se utilizam dados novos o modelo não se adapta bem)\n",
    "\n",
    "np.std(scores[\"test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augumentation - Alteração das caracteristicas das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altera as imagens. As novas imagens são geradas a partir das existentes aplicando rotações, aumento do zoom, alteração da \n",
    "# direcção dos pixeis, etc.\n",
    "\n",
    "# Augmentation não se refere ao processo de aumentar o número total de imagens. É o processo de criar diferentes variantes das\n",
    "# imagens originais(aplicando rotações, zoom, etc.). As imagens geradas não são totalmente diferentes das originais mas uma\n",
    "# transformação aleatoria delas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações nas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotation_range: grau de rotação das imagens originais\n",
    "# horizontal_flip: rotações horizontais\n",
    "# shear_range: mudar a direcção dos pixeis\n",
    "# height_shift_range: modificar a faixa de altura da imagem\n",
    "# zoom_range: alterar o zoom da imagem\n",
    "\n",
    "train_data_base_generator = preprocessing.image.ImageDataGenerator(rotation_range=7, horizontal_flip=True, shear_range=0.2,\n",
    "                                                         height_shift_range=0.07, zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como não se utilizaram parâmetros não faz alterações na imagem. Mantem as imagens originais.\n",
    "test_data_base_generator = preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar nova base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um base de dados de treino a partir das imagens originais(X_train, y_train)\n",
    "\n",
    "# batch_size: 150, calcula-se o erro de um conjunto de 150 dados e actualizam-se todos os pesos e escolhe-se um detector de \n",
    "# caracteristicas melhor. De seguida calcula-se o erro para o seguinte conjunto de 150 dados e actualizam-se todos os pesos e \n",
    "# escolhe-se um detector de caracteristicas melhor. E assim sucessivamente.\n",
    "\n",
    "train_data_base = train_data_base_generator.flow(X_train, y_train, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um base de dados de teste a partir das imagens originais(X_test, y_test)\n",
    "test_data_base = test_data_base_generator.flow(X_test, y_test, batch_size=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), input_shape=(28, 28, 1), activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(layers.Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "400/400 [==============================] - 41s 103ms/step - loss: 0.5785 - accuracy: 0.8163 - val_loss: 0.1968 - val_accuracy: 0.9368\n",
      "Epoch 2/4\n",
      "400/400 [==============================] - 39s 96ms/step - loss: 0.2429 - accuracy: 0.9236 - val_loss: 0.1125 - val_accuracy: 0.9651\n",
      "Epoch 3/4\n",
      "400/400 [==============================] - 41s 104ms/step - loss: 0.1809 - accuracy: 0.9450 - val_loss: 0.0995 - val_accuracy: 0.9679\n",
      "Epoch 4/4\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 0.1444 - accuracy: 0.9553 - val_loss: 0.0792 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x3d1b6a6630>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Em vez do model.fit() utiliza-se o model.fit_generator()\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# epochs: Quantas vezes o algoritmo percorre o conjunto de dados de treino totalmente e escolhe-se um detector de \n",
    "# carateristicas melhor. \n",
    "\n",
    "# 1ª epoca- calcula o erro para os primeiros 150 dados e actualiza todos os pesos e escolhe-se um detector de caracteristicas \n",
    "# melhor. Calcula o o erro para os 150 dados seguintes e actualiza todos os pesos e escolhe-se um detector de caracteristicas \n",
    "# melhor. E assim sucessivamente.\n",
    "# 2ª epoca- calcula o erro para os primeiros 150 dados(com os pesos da 1ª epoca) e actualiza todos os pesos e escolhe-se um\n",
    "# detector de caracteristicas melhor(melhor do que o obtido na 1ª epoca).\n",
    "# Calcula o o erro para os 150 dados seguintes(com os pesos da 1ª epoca) e actualiza todos os pesos e detector de \n",
    "# caracteristicas. E assim sucessivamente.\n",
    "# 6000/150 = 40 batchs. Os pesos e o detector de caracteristicas são actualizados 40 vezes em cada epoca.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# steps_per_epoch: 60000/150 = 400 \n",
    "# Número de iterações por epoca. Garante que apenas as primerias 400 amostras(batchs) são consideradas. É util quando se tem um\n",
    "# conjunto de dados demasiado grande para ser processado.\n",
    "# 1ª epoca: calcula o erro para os primeiros 150 dados e actualiza todos os pesos e escolhe-se um detector de caracteristicas \n",
    "# melhor. Calcula o o erro para os 150 dados seguintes e actualiza todos os pesos e escolhe-se um detector de caracteristicas \n",
    "# melhor. E assim sucessivamente até terem sido realizadas 400 iterações. Ou seja apenas se consideraram as primeiras 60000\n",
    "# imagens.\n",
    "# Assim as 60000 imagens originais são transformadas por epoca. \n",
    "\n",
    "# Com o steps_per_epoch=n_samples/batch_size em cada epoca cada amostra é transformada apenas uma vez e portanto neste caso\n",
    "# vão ser geradas 60000 imagens transformadas a cada epoca. Essas imagens vão ser as usadas para se fazer o treino. Na proxima\n",
    "# epoca uma nova transformação aleatoria das 60000 imagens é feita e o treino é feito com essas imagens tranformadas.\n",
    "# Ou seja não se está a aumentar o número de imagens de treino de 60000 para um número maior, mas a fazer o treino em 60000\n",
    "# imagens que são transformadas de epoca para epoca.\n",
    "\n",
    "# Por exemplo na primeira epoca a 1ª imagem orinal é transformada aleatoriamente e faz-se o treino com base nessa transformação.\n",
    "# Na segunda epoca a 1ª imagem orinal volta a ser transformada aleatoriamentee e faz-se o treino com base nessa transformação.\n",
    "# E assim sucessivamente.\n",
    "# Para 5 epocas cada imagem é transformada 5 vezes.\n",
    "\n",
    "# Não faz sentido alterar o steps_per_epoch=n_samples/batch_size para um valor diferente.\n",
    "# Por exemplo ao se escolher o steps_per_epoch=2x(n_samples/batch_size) para aumentar o número de transformações que uma imagem\n",
    "# sofre por epoca(de 1 transformação para 2). Esta-se a fazer com que cada epoca seja 2 epocas normais. Ou seja, deveria-se\n",
    "# aumentar o númemro de epocas e não o steps_per_epoch.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#validation_steps: Semelhante ao steps_per_epoch mas aplicado ao conjunto de dados de teste.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Validation data: Avaliação do modelo utilizando a base de dados de teste (val_accuracy).\n",
    "\n",
    "# Ajustar os dados de entrada de treino aos dados de saida para treinar o modelo(Estão os dois na base de dados de treino).\n",
    "model.fit_generator(train_data_base, steps_per_epoch=60000/150, epochs=4, validation_data=test_data_base, \n",
    "                    validation_steps=10000/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
