{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação Multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, datasets, utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A base de dados já está dividida em dois conjuntos: treino e teste\n",
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50000 imagens para treino\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10000 imagens para teste\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xc63f7619e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Camião a cores\n",
    "plt.imshow(X_train[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz com os pixeis da imagem com o camião\n",
    "# Imagem 32x32\n",
    "# rgb 3\n",
    "pixeis = X_train[1]\n",
    "pixeis.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1º parametro: número de imagens\n",
    "# 2º parametro: Altura da imagem (nº de pixeis da imagem na vertical).\n",
    "# 3º parametro: Largura da imagem (nº de pixeis da imagem na horizontal).\n",
    "# Nº de canais de RGB: 3 para imagens a cores.\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão dos dados do tipo int8 para float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151, 110,  40], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como os dados vão ser convertidos para uma escala entre 0 e 1 tem-se de converter os dados de inteiro8 para float32 para que\n",
    "# os valores obtidos depois da normalização não sejam inteiros e consequentemente quase todos 0(por não haver números decimais).\n",
    "\n",
    "X_test[0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão dos dados em float 32\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151., 110.,  40.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos pixeis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passar os pixeis para uma escala de 0 a 1 para que o precessamento dos dados seja mais rapido\n",
    "# Isto pode ser feito através da tecnica min max normalization. Como cada pixel ocupa 1 byte e o byte consegue guardar 256\n",
    "# resultados possiveis(ou seja varia entre 0 e 255). \n",
    "# A normalização pode ser feita dividindo o pixel por 255 (tambem se podia utilizar o skit-learn).\n",
    "\n",
    "# Pode-se ver que o valor máximo de um pixel é de 255\n",
    "X_test[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização do conjunto de teste e treino\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "X_test[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação de variaveis em dummys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como se trata de um problema de multiplas classes, cada classe tem de ter a probabilidade de pertencer a objecto.\n",
    "# tem de ser um vector [50000,10] e [10000,10] (exigencia da biblioteca) e não se pode utilizar o LabelEncoder.\n",
    "\n",
    "# As 10 classes do problema (já foram passadas de categoricas para númericas, não sendo necessario aplicar o LabelEncoder\n",
    "# antes de transformar as variaveis em dummies).\n",
    "# avião, automóvel, pássaro, gato, veado, cachorro, sapo, cavalo, navio e caminhão\n",
    "\n",
    "\n",
    "# número 1: 1 0 0 0 0 0 0 0 0 0\n",
    "# número 2: 0 1 0 0 0 0 0 0 0 0\n",
    "# ....\n",
    "# número 0: 0 0 0 0 0 0 0 0 0 1\n",
    "\n",
    "# tambem se podia utilizar o pd.get_dummies()\n",
    "y_train = utils.to_categorical(y_train, 10)\n",
    "y_test = utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN com 2 camadas de convolução e 2 camadas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential - uma cada apos a outra\n",
    "# dense - camadas fully conected, cada neuronio esta conectado a todos os neuronios da camada seguinte\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de convolução (conv2D porque é uma imagem):\n",
    "\n",
    "# Operador de convolução: multiplicação da imagem(matriz de pixeis 28x28) por um detector de caracteristicas, feature detection\n",
    "# ou filtro ou kernel(matriz normalmente 3x3 para imagens pequenas) que vai originar um mapa de caracteristicas.\n",
    "# Este mapa tem como objectivo filtrar(detectar) as caracteristicas mais importantes da imagem. \n",
    "\n",
    "# Detectores de caracteristicas:32, Utilizam-se 32 matrizes de detectores de caraceristicas que vão originar 32 mapas de\n",
    "# caracteristicas. Estes detectores de caracteristicas são originados variando os números da matriz até se obter aquele que \n",
    "# apresenta o melhor resultado. O recomendado é utilizar 64 kernels e seus multiplos(128, 256, 512, 1024, etc).\n",
    "\n",
    "# Kernel_size: (3,3) matriz detectora de caracteristicas do tamanho 3x3 \n",
    "\n",
    "# strider: (1,1) Os valores do mapa de caracteristicas são obtidos com a subdivisão da matriz da imagem a fazer-se movendo um \n",
    "# pixel para a direita e um pixel para baixo.\n",
    "\n",
    "# input_shape: dimensões da imagem e número de canais(1 para imagens sem cor e 3 para imagens com cor)\n",
    "\n",
    "# função de activação: Aplica a função relu(transforma valores negativos em zero e mantem os restantes iguais) ao mapa de \n",
    "# caracteristicas. Isto permite detectar melhor os padrões(Transforma os pontos mais escuros(com valores negativos) em pontos \n",
    "# mais claros e mais parecidos com os restantes pontos).\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada de Normalização\n",
    "# A normalização dos já foi feita anteriormente para a camada de entrada. Essa normalização tambem pode ser feita para as \n",
    "# camadas de convoluções, a normalização é feita no mapa de caracteristicas onde todos os valores passam a estar entre 0 e 1. \n",
    "# Isto faz com que o processamento do algoritmo seja mais rapido.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de Pooling\n",
    "# O mapa de caracteristicas(neste caso 5x5) é percorrido por uma matriz(neste caso 2x2) para encontrar os valores maiores\n",
    "#(caracteristicas mais importantes) e formar um nova matriz com esses valores(Poolin matrix).  \n",
    "# Os valores da matriz de pooling são obtidos com a subdivisão do mapa de caracteristicas a fazer-se movendo uma coluna para a\n",
    "# direita e uma coluna para baixo.\n",
    "# Como neste caso tem-se 32 mapas de caracteristicas tem-se igual número de matrizes de pooling.\n",
    "\n",
    "# Utiliza-se o Max Pooling para se obter o maior valor e assim realçar as caracteristicas principais da imagem. (tambem se podia\n",
    "# utilizar a média ou o minimo valor).\n",
    "\n",
    "# pool_size: (2,2) tamanho da matriz utilizada para seleccionar as carateristicas do mapa de caracteristicas. Vai originar uma\n",
    "# matriz pooling.\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada de Flattening\n",
    "\n",
    "# Transformar a matriz de pooling num vector que irá ser utilizado na camada de entrada da rede neural densa.\n",
    "# Os valores dos neuronios da camada de entrada da rede neural serão os valores desse vector.\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1ª camada oculta\n",
    "# número de neuronios para primeira modelação: Optou-se por colocar 128 neuronios.\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada Dropout\n",
    "# Ajuda a prevenir o overfitting(que em redes neurais convolucionais tem grande probabilidade de acontecer devido aos muitos\n",
    "# parametros que se utilizam).\n",
    "# Coloca-se zeros em alguns valores/neuronios da camada de entrada de forma aleatoria. Escolhe-se a quantidade/percentagem de \n",
    "# neuronios que terão valor zero. Ao se colocar o valor zero estes neuronios não teram influencia no modelo. Normalmente \n",
    "# utiliza-se uma percentagem entre 20% a 30%. Se for demasiado elevado(maior que 50%) o modelo pode entrar em underfitting, \n",
    "# porque não consegue aprender, pois tem demasiadas entradas que não são consideradas.\n",
    "# Como se utilizam menos variaveis é mais dificil haver alguma que não tenham sido treinada e que o modelo não consiga prever.\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de Saida\n",
    "# Neuronios: Igual ao número de saidas possiveis, neste caso são 10 classes.\n",
    "# Função de activação: softmax é a função utilizada para problemas de classificação multiclasse. Para se obter a probabilidade\n",
    "# para cada uma das classes (por ex. para um neurónio tem-se a probabilidade de 10% de ser avião, 80% gato e 10% de ser sapo).\n",
    "# A classe atribuida será aquela que tem maior probabilidade.\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1º: Multiplicação da imgem(input) pela detector de caracteristicas para obter o mapa de caracteristicas\n",
    "# 2º: Percorrer o mapa de caracteristicas com uma matriz para encontrar os valores maiores e formar a matriz de pooling\n",
    "# 3º: Multiplicar a matriz de pooling pelo detector de caracteristicas para obter o mapa de caracteristicas mais refinado\n",
    "# 4º: Percorrer o mapa de caracteristicas com uma matriz para encontrar os valores maiores e formar a matriz de pooling mais\n",
    "# refinada\n",
    "\n",
    "# 5º: trasformar a matriz de pooling refinada num vector para servir de camada de entrada da rede neural densa\n",
    "# 6º: multiplicar os valores do vector pelos pesos para obter a função soma e aplicar a função relu a esse resultado para obter\n",
    "# o valor de cada neurónio da 1ª camada oculta\n",
    "# 7º: multiplicar os valores dos neuronios da 1ª camada oculta pelos pesos para obter a função soma e aplicar a função \n",
    "# relu a esse resultado para obter o valor de cada neurónio da 2ª camada oculta\n",
    "# 8º: multiplicar os valores dos neuronios da 2ª camada oculta pelos pesos para obter a função soma de cada neuronio da camada\n",
    "# de saida. Aplicar a função softmax aos resultados da função para obter a probabilidade do neuronio pertencer à classe que se\n",
    "# definiu.\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), input_shape=(32, 32, 3), activation=\"relu\")) # 1ª camada de convolução e definição da camada\n",
    "model.add(layers.BatchNormalization())                                          # de entrada\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation=\"relu\")) # 2ª camada de convolução\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten()) # funciona como camada de entrada da rede neural oculta\n",
    "\n",
    "model.add(layers.Dense(units=128, activation=\"relu\")) # 1ª camada de oculta\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(units=128, activation=\"relu\")) # 2ª camada de oculta\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(units=10, activation=\"softmax\")) # camada de saida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilação e Ajuste do modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 15:50:48.501617  7876 deprecation.py:323] From C:\\Users\\Bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 226s 5ms/sample - loss: 1.5785 - accuracy: 0.4359 - val_loss: 1.9539 - val_accuracy: 0.3511\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 221s 4ms/sample - loss: 1.2162 - accuracy: 0.5700 - val_loss: 1.2122 - val_accuracy: 0.5723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7c5d581518>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar os dados de entrada de treino aos dados de saida de treino para treinar o modelo\n",
    "model.fit(X_train, y_train, batch_size=150, epochs=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão e Avaliação do Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.05522907e-01, 1.06823975e-02, 6.13992149e-03, 9.47774970e-04,\n",
       "       1.36774185e-03, 6.26927504e-05, 1.13833252e-04, 9.26773791e-05,\n",
       "       4.70672548e-01, 4.39754082e-03], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prever os dados de teste para avaliar o modelo\n",
    "predictions = model.predict(X_test)\n",
    "predictions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 8, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de modo a se poder utilizar a matriz de confusão e o relatorio de classificação para avaliar o modelo tem-se de transformar \n",
    "# o vectores prediction e y_teste do formato [10000,10] para [10000,1] (exigencia da biblioteca sklearn).\n",
    "\n",
    "# Retorna o número do indice que tem a probabilidade mais alta.\n",
    "predictions_index = [np.argmax(index) for index in np.array(predictions)]\n",
    "predictions_index[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 8, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retorna o número do indice que tem a probabilidade mais alta.\n",
    "y_test_index = [np.argmax(index) for index in np.array(y_test)]\n",
    "y_test_index[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction index</th>\n",
       "      <th>teste index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction index  teste index\n",
       "0                 3            3\n",
       "1                 8            8\n",
       "2                 8            8\n",
       "3                 0            0\n",
       "4                 4            6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparação entre os indices obtidos usando o X_test(predicion) e y_test(reais).\n",
    "pd.DataFrame({\"prediction index\": predictions_index, \"teste index\":y_test_index}).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.55      0.57      1000\n",
      "           1       0.70      0.74      0.72      1000\n",
      "           2       0.61      0.31      0.41      1000\n",
      "           3       0.47      0.42      0.44      1000\n",
      "           4       0.45      0.65      0.53      1000\n",
      "           5       0.63      0.40      0.49      1000\n",
      "           6       0.83      0.50      0.62      1000\n",
      "           7       0.61      0.67      0.64      1000\n",
      "           8       0.47      0.90      0.62      1000\n",
      "           9       0.63      0.60      0.62      1000\n",
      "\n",
      "   micro avg       0.57      0.57      0.57     10000\n",
      "   macro avg       0.60      0.57      0.57     10000\n",
      "weighted avg       0.60      0.57      0.57     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Relatório de classificação\n",
    "#Ver como o modelo se ajusta para os dados de teste\n",
    "print(classification_report(y_test_index, predictions_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test_index,predictions_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>Predicted</th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Avião</th>\n",
       "      <th>Automovel</th>\n",
       "      <th>Pássaro</th>\n",
       "      <th>Gato</th>\n",
       "      <th>Veado</th>\n",
       "      <th>Cão</th>\n",
       "      <th>Sapo</th>\n",
       "      <th>Cavalo</th>\n",
       "      <th>Navio</th>\n",
       "      <th>Camião</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\"></th>\n",
       "      <th>Avião</th>\n",
       "      <td>546</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>333</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automovel</th>\n",
       "      <td>18</td>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pássaro</th>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "      <td>310</td>\n",
       "      <td>65</td>\n",
       "      <td>229</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gato</th>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>417</td>\n",
       "      <td>130</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>104</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th>Veado</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>646</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>125</td>\n",
       "      <td>63</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\"></th>\n",
       "      <th>Cão</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>237</td>\n",
       "      <td>98</td>\n",
       "      <td>398</td>\n",
       "      <td>11</td>\n",
       "      <td>106</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sapo</th>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>73</td>\n",
       "      <td>224</td>\n",
       "      <td>13</td>\n",
       "      <td>496</td>\n",
       "      <td>29</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cavalo</th>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>94</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>671</td>\n",
       "      <td>32</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Navio</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>901</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camião</th>\n",
       "      <td>38</td>\n",
       "      <td>149</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>163</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Predicted                   \\\n",
       "                 Avião Automovel Pássaro Gato     Veado  Cão Sapo Cavalo   \n",
       "       Avião       546        35      27   12         9    1    3     13   \n",
       "       Automovel    18       736       1    6         6    3    4      6   \n",
       "       Pássaro     119        20     310   65       229   53   29     59   \n",
       "       Gato         34        25      39  417       130   98   35     68   \n",
       "Actual Veado        55         7      29   35       646   14   14    125   \n",
       "       Cão          20        10      45  237        98  398   11    106   \n",
       "       Sapo         17        24      31   73       224   13  496     29   \n",
       "       Cavalo       27         7      16   38        94   51    2    671   \n",
       "       Navio        32        32       4    2         2    2    2      7   \n",
       "       Camião       38       149       3   11        11    3    1     19   \n",
       "\n",
       "                               \n",
       "                 Navio Camião  \n",
       "       Avião       333     21  \n",
       "       Automovel   118    102  \n",
       "       Pássaro      93     23  \n",
       "       Gato        104     50  \n",
       "Actual Veado        63     12  \n",
       "       Cão          52     23  \n",
       "       Sapo         55     38  \n",
       "       Cavalo       32     62  \n",
       "       Navio       901     16  \n",
       "       Camião      163    602  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matriz de confusão\n",
    "outside_columns = [\"\",\"\",\"\",\"\",\"Predicted\",\"\",\"\",\"\",\"\",\"\"]\n",
    "outside_index = [\"\",\"\",\"\",\"\",\"Actual\",\"\",\"\",\"\",\"\",\"\"]\n",
    "inside = [\"Avião\",\"Automovel\",\"Pássaro\",\"Gato\",\"Veado\",\"Cão\",\"Sapo\",\"Cavalo\",\"Navio\",\"Camião\"]\n",
    "\n",
    "hier_columns = list(zip(outside_columns, inside))\n",
    "hier_columns = pd.MultiIndex.from_tuples(hier_columns)\n",
    "\n",
    "hier_index = list(zip(outside_index, inside))\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)\n",
    "\n",
    "pd.DataFrame(confusion, columns=hier_columns, index = hier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 420us/sample - loss: 1.2122 - accuracy: 0.5723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2122385873794557, 0.5723]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Com o TensorFlow 2.0 pode-se avaliar o modelo de forma mais expedita através do método evaluate. \n",
    "# Sem ser necessário criar o relatorio de classificação e as respectivas transformações na variavel de saida (transformar o \n",
    "# array de [10000,3] para [10000,1].\n",
    "# Os métodos de avaliação podem ser definidos quando se cria o modelo (neste caso escolheu-se apenas a accuracy).\n",
    "# Esta avaliação tambem foi feita no ajuste do modelo ao defenir-se o validation_data.\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsão de uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1º parâmetro: Altura da imagem (nº de pixeis da imagem na vertical).\n",
    "# 2º parâmetro: Largura da imagem (nº de pixeis da imagem na horizontal).\n",
    "# 3º parâmetro: Escala rgb: 3 para imagens a cores.\n",
    "\n",
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionar uma nova dimenção ao array com a imagem\n",
    "\n",
    "# 1º parâmetro: número de imagens\n",
    "# 2º parâmetro: Altura da imagem (nº de pixeis da imagem na vertical).\n",
    "# 3º parâmetro: Largura da imagem (nº de pixeis da imagem na horizontal).\n",
    "# 4º parâmetro: Escala rgb: 3 para imagens a cores\n",
    "\n",
    "image = np.expand_dims(X_test[6],axis = 0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7c0f524470>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualização do número da imagem\n",
    "plt.imshow(X_test[6].reshape(32,32,3), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previsão da classe da imagem\n",
    "\n",
    "# Como é um problema de classificação multiclasse(utilizou-se a função softmax), considera-se que a imagem pertence à classe que\n",
    "# tem a probabilidade mais alta(pode-se utilizar o argmax, para saber o indice do array com o maior valor).\n",
    "result = model.predict(image)\n",
    "result.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função com as classes das imagens\n",
    "\n",
    "def name():\n",
    "    if result.argmax() == 0:\n",
    "        print(\"Avião\")\n",
    "    if result.argmax() == 1:\n",
    "        print(\"Automóvel\")\n",
    "    if result.argmax() == 2:\n",
    "        print(\"Pássaro\")\n",
    "    if result.argmax() == 3:\n",
    "        print(\"Pato\")   \n",
    "    if result.argmax() == 4:\n",
    "        print(\"Veado\")\n",
    "    if result.argmax() == 5:\n",
    "        print(\"Cão\")\n",
    "    if result.argmax() == 6:\n",
    "        print(\"Sapo\")       \n",
    "    if result.argmax() == 7:\n",
    "        print(\"Cavalo\")   \n",
    "    if result.argmax() == 8:\n",
    "        print(\"Navio\")\n",
    "    if result.argmax() == 9:\n",
    "        print(\"Camião\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automóvel\n"
     ]
    }
   ],
   "source": [
    "# Previsão do objecto na imagem\n",
    "name()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
