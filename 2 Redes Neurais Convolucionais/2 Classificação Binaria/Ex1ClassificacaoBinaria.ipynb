{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação Binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import layers, models, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augumentation - Alteração das caracteristicas das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2000 imagens de gatos e 2000 de cães. É uma quantidade pequena de imagens. Utiliza-se o Augmentation para o treino ser feito\n",
    "# em cada epoca com imagens diferentes das originais. Deste modo apesar de o treino ser feito com a mesma quantidade de imagens\n",
    "# (2000) em cada epoca é utilizada uma versão diferente dessas imagens.\n",
    "\n",
    "# Altera as imagens. As novas imagens são geradas a partir das existentes aplicando rotações, aumento do zoom, alteração da \n",
    "# direcção dos pixeis, etc.\n",
    "\n",
    "# Augmentation não se refere ao processo de aumentar o número total de imagens. É o processo de criar diferentes variantes das\n",
    "# imagens originais(aplicando rotações, zoom, etc.). As imagens geradas não são totalmente diferentes das originais mas uma\n",
    "# transformação aleatoria delas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações nas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale: fazer a normalização dos pixeis para que os seus valores variem entre 0 e 1 (O ImageDataGenerato pode ser utilizado\n",
    "# apenas para fazer a normalização dos pixeis e manter as imagens originais(para não estar manualmente a importar as imagens e \n",
    "# dividir o se número de pixeis por 255).\n",
    "\n",
    "# rotation_range: grau de rotação das imagens originais\n",
    "# horizontal_flip: rotações horizontais\n",
    "# shear_range: mudar a direcção dos pixeis\n",
    "# height_shift_range: modificar a faixa de altura da imagem\n",
    "# zoom_range: alterar o zoom da imagem\n",
    "\n",
    "train_data_base_generator = preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=7, horizontal_flip=True, \n",
    "                                                                   shear_range=0.2, height_shift_range=0.07, zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como não se utilizaram parâmetros não faz alterações na imagem. Mantem as imagens originais.\n",
    "# Como as imagens de treino devem ser diferentes das imagens de teste(apenas devem ter a mesma escala) não é necessário fazer \n",
    "# alterações na base de dados de teste.\n",
    "test_data_base_generator = preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar nova base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Criar um base de dados de treino a partir das imagens originais(X_train, y_train)\n",
    "\n",
    "# Pode ser usado apenas para importar as imagens sem nenhuma alteração, para não se fazer a divisão em teste e treino \n",
    "# manualmente.\n",
    "\n",
    "# batch_size: 32, calcula-se o erro de um conjunto de 32 dados e actualizam-se todos os pesos e escolhe-se um detector de \n",
    "# caracteristicas melhor. De seguida calcula-se o erro para o seguinte conjunto de 32 dados e actualizam-se todos os pesos e \n",
    "# escolhe-se um detector de caracteristicas melhor. E assim sucessivamente.\n",
    "\n",
    "# target_size: tamanho das imagens(igual ao definido na rede neural).\n",
    "# class_mode: binary para problemas de classificação binária.\n",
    "\n",
    "train_data_base = train_data_base_generator.flow_from_directory(\"dataset/training_set\",target_size=(64,64), batch_size=32,\n",
    "                                                               class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_base = test_data_base_generator.flow_from_directory(\"dataset/test_set\",target_size=(64,64), batch_size=32,\n",
    "                                                               class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN com 2 camadas de convolução e 1 camada oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential - uma cada apos a outra\n",
    "# dense - camadas fully conected, cada neuronio esta conectado a todos os neuronios da camada seguinte\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de convolução (conv2D porque é uma imagem):\n",
    "\n",
    "# Existem imagens com dimensões diferentes. Optou-se por utilizar a dimensão 64x64 pixeis para todas as imagens (todas as \n",
    "# imagens têm de ter as mesmas dimensões para a rede neural aplicar os calculos matemáticos).\n",
    "\n",
    "# Operador de convolução: multiplicação da imagem(matriz de pixeis 64x64) por um detector de caracteristicas, feature detection\n",
    "# ou filtro ou kernel(matriz normalmente 3x3 para imagens pequenas) que vai originar um mapa de caracteristicas.\n",
    "# Este mapa tem como objectivo filtrar(detectar) as caracteristicas mais importantes da imagem. \n",
    "\n",
    "# Detectores de caracteristicas:32, Utilizam-se 32 matrizes de detectores de caraceristicas que vão originar 32 mapas de\n",
    "# caracteristicas. Estes detectores de caracteristicas são originados variando os números da matriz até se obter aquele que \n",
    "# apresenta o melhor resultado. O recomendado é utilizar 64 kernels e seus multiplos(128, 256, 512, 1024, etc).\n",
    "\n",
    "# Kernel_size: (3,3) matriz detectora de caracteristicas do tamanho 3x3 \n",
    "\n",
    "# strider: (1,1) Os valores do mapa de caracteristicas são obtidos com a subdivisão da matriz da imagem a fazer-se movendo um \n",
    "# pixel para a direita e um pixel para baixo.\n",
    "\n",
    "# input_shape: dimensões da imagem e número de canais(1 para imagens sem cor e 3 para imagens com cor)\n",
    "\n",
    "# função de activação: Aplica a função relu(transforma valores negativos em zero e mantem os restantes iguais) ao mapa de \n",
    "# caracteristicas. Isto permite detectar melhor os padrões(Transforma os pontos mais escuros(com valores negativos) em pontos \n",
    "# mais claros e mais parecidos com os restantes pontos).\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada de Normalização\n",
    "# A normalização dos já foi feita anteriormente para a camada de entrada(com X_train/255 e X_test/255). Essa normalização tambem\n",
    "# pode ser feita para as camadas de convoluções, a normalização é feita no mapa de caracteristicas onde todos os valores passam \n",
    "# a estar entre 0 e 1. \n",
    "# Isto faz com que o processamento do algoritmo seja mais rapido.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de Pooling\n",
    "# O mapa de caracteristicas é percorrido por uma matriz(neste caso 2x2) para encontrar os valores maiores\n",
    "# (caracteristicas mais importantes) e formar um nova matriz com esses valores(Poolin matrix).  \n",
    "# Os valores da matriz de pooling são obtidos com a subdivisão do mapa de caracteristicas a fazer-se movendo uma coluna para a\n",
    "# direita e uma coluna para baixo.\n",
    "# Como neste caso tem-se 32 mapas de caracteristicas tem-se igual número de matrizes de pooling.\n",
    "\n",
    "# Utiliza-se o Max Pooling para se obter o maior valor e assim realçar as caracteristicas principais da imagem. (tambem se podia\n",
    "# utilizar a média ou o minimo valor).\n",
    "\n",
    "# pool_size: (2,2) tamanho da matriz utilizada para seleccionar as carateristicas do mapa de caracteristicas. Vai originar uma\n",
    "# matriz pooling.\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada de Flattening\n",
    "\n",
    "# Transformar a matriz de pooling num vector que irá ser utilizado na camada de entrada da rede neural densa.\n",
    "# Os valores dos neuronios da camada de entrada da rede neural serão os valores desse vector.\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1ª camada oculta\n",
    "# número de neuronios para primeira modelação:\n",
    "# Optou-se por colocar 128 neuronios.\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada Dropout\n",
    "# Ajuda a prevenir o overfitting(que em redes neurais convolucionais tem grande probabilidade de acontecer devido aos muitos\n",
    "# parametros que se utilizam).\n",
    "# Coloca-se zeros em alguns valores/neuronios da camada de entrada de forma aleatoria. Escolhe-se a quantidade/percentagem de \n",
    "# neuronios que terão valor zero. Ao se colocar o valor zero estes neuronios não teram influencia no modelo. Normalmente \n",
    "# utiliza-se uma percentagem entre 20% a 30%. Se for demasiado elevado(maior que 50%) o modelo pode entrar em underfitting, \n",
    "# porque não consegue aprender, pois tem demasiadas entradas que não são consideradas.\n",
    "# Como se utilizam menos variaveis é mais dificil haver alguma que não tenham sido treinada e que o modelo não consiga prever.\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Camada de Saida\n",
    "# Neuronios: Igual ao número de saidas possiveis, para classificação binária normalmente utiliza-se 1. Considera-se o resultado \n",
    "# obtido ser da classe A se for 0 (<0.5) e 1 (>=0.5) é considerado classe B (no caso de se usar a função sigmoid nesta camada).\n",
    "# Função de activação: Sigmoid porque é um problema de classificação binário que varia entre 0 e 1, e esta função retorna sempre\n",
    "# um valor entre 0 e 1.\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), input_shape=(64, 64, 3), activation=\"relu\")) # 1ª camada de convolução e definição da camada\n",
    "model.add(layers.BatchNormalization())                                          # de entrada\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation=\"relu\")) # 2ª camada de convolução\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten()) # funciona como camada de entrada da rede neural oculta\n",
    "\n",
    "model.add(layers.Dense(units=128, activation=\"relu\")) # 1ª camada de oculta\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(units=1, activation=\"sigmoid\")) # camada de saida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilação e Ajuste do modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0705 13:26:33.273961  7780 deprecation.py:323] From C:\\Users\\Bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 117s 936ms/step - loss: 0.8126 - accuracy: 0.6040 - val_loss: 2.4947 - val_accuracy: 0.5000\n",
      "Epoch 2/4\n",
      "125/125 [==============================] - 100s 804ms/step - loss: 0.6346 - accuracy: 0.6405 - val_loss: 1.3341 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "125/125 [==============================] - 114s 914ms/step - loss: 0.5979 - accuracy: 0.6862 - val_loss: 0.8414 - val_accuracy: 0.6190\n",
      "Epoch 4/4\n",
      "125/125 [==============================] - 92s 739ms/step - loss: 0.5754 - accuracy: 0.7007 - val_loss: 0.8850 - val_accuracy: 0.6380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x70b5a9ca20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Em vez do model.fit() utiliza-se o model.fit_generator()\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# epochs: Quantas vezes(iterações) se ajustam os valores de todos os pesos e escolhe-se um detector de carateristicas melhor. \n",
    "# Ou seja quantas vezes se faz o treino dos dados com os valores dos pesos a serem melhorados e a escolher-se(mudar-se) o \n",
    "# detector de caracteristicas.\n",
    "\n",
    "# 1ª epoca- calcula o erro para os primeiros 32 dados e actualiza os pesos. Calcula o o erro para os 32 dados seguintes e \n",
    "# actualiza os pesos. E assim sucessivamente. Actualiza-se(muda-se) o detector de caracteristica no fim desta época.\n",
    "# 2ª epoca- calcula o erro para os primeiros 32 dados(com os pesos da 1ª epoca) e actualiza os pesos. Calcula o o erro para os\n",
    "# 32 dados seguintes(com os pesos da 1ª epoca) e actualiza-se os pesos. E assim sucessivamente. Actualiza-se(muda-se) o\n",
    "# detector de caracteristica no fim desta época.\n",
    "\n",
    "# 4000/32 = 125 batchs. Os pesos e o detector de caracteristicas são actualizados 125 vezes em cada epoca.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# steps_per_epoch: 4000/32 = 125\n",
    "# Número de iterações por epoca. Garante que apenas as primerias 125 amostras(batchs) são consideradas. É util quando se tem um\n",
    "# conjunto de dados demasiado grande para ser processado.\n",
    "# 1ª epoca: calcula o erro para os primeiros 32 dados e actualiza os pesos (O detector de caracteristicas só é actualizado\n",
    "# no fim de cada época). Calcula o o erro para os 32 dados seguintes e actualiza os pesos.\n",
    "# E assim sucessivamente até terem sido realizadas 125 iterações. Ou seja apenas se consideraram as primeiras 4000\n",
    "# imagens.\n",
    "# Assim as 4000 imagens originais são transformadas por epoca. \n",
    "\n",
    "# Com o steps_per_epoch=n_samples/batch_size em cada epoca cada amostra é transformada apenas uma vez e portanto neste caso\n",
    "# vão ser geradas 4000 imagens transformadas a cada epoca. Essas imagens vão ser as usadas para se fazer o treino. Na proxima\n",
    "# epoca uma nova transformação aleatoria das 4000 imagens é feita e o treino é feito com essas imagens tranformadas.\n",
    "# Ou seja não se está a aumentar o número de imagens de treino de 4000 para um número maior, mas a fazer o treino em 4000\n",
    "# imagens que são transformadas de epoca para epoca.\n",
    "\n",
    "# Por exemplo na primeira epoca a 1ª imagem orinal é transformada aleatoriamente e faz-se o treino com base nessa transformação.\n",
    "# Na segunda epoca a 1ª imagem orinal volta a ser transformada aleatoriamente e faz-se o treino com base nessa transformação.\n",
    "# E assim sucessivamente.\n",
    "# Para 5 epocas cada imagem é transformada 5 vezes.\n",
    "\n",
    "# Não faz sentido alterar o steps_per_epoch=n_samples/batch_size para um valor diferente.\n",
    "# Por exemplo ao se escolher o steps_per_epoch=2x(n_samples/batch_size) para aumentar o número de transformações que uma imagem\n",
    "# sofre por epoca(de 1 transformação para 2). Esta-se a fazer com que cada epoca seja 2 epocas normais. Ou seja, deveria-se\n",
    "# aumentar o númemro de epocas e não o steps_per_epoch.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#validation_steps: Semelhante ao steps_per_epoch mas aplicado ao conjunto de dados de teste.\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Validation data: Avaliação do modelo utilizando a base de dados de teste (val_accuracy).\n",
    "\n",
    "# Ajustar os dados de entrada de treino aos dados de saida para treinar o modelo(Estão os dois na base de dados de treino).\n",
    "model.fit_generator(train_data_base, steps_per_epoch=4000/32, epochs=4, validation_data=test_data_base, \n",
    "                    validation_steps=1000/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão de uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x70B77FD978>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar uma imagem de teste\n",
    "image_test = preprocessing.image.load_img(\"dataset/test_set/cachorro/dog.3500.jpg\", target_size=(64,64))\n",
    "image_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converter o formato da imagem de Image para array\n",
    "image_test = preprocessing.image.img_to_array(image_test)\n",
    "image_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização dos pixeis\n",
    "image_test = image_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionar uma nova dimenção ao array com a imagem\n",
    "\n",
    "# 1º parâmetro: número de imagens\n",
    "# 2º parâmetro: Altura da imagem (nº de pixeis da imagem na vertical).\n",
    "# 3º parâmetro: Largura da imagem (nº de pixeis da imagem na horizontal).\n",
    "# 4º parâmetro: Escala rgb: 1 para escala de cinzentos.\n",
    "\n",
    "image_test = np.expand_dims(image_test, axis = 0)\n",
    "image_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37488317]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilidade da imagem pertencer à classe 1 ou classe 0.\n",
    "# Como é um problema de classificação binária(utilizou-se a função sigmoid) quanto mas proximo do 1 estiver a previsão maior\n",
    "# é a probabilidade da imagem pertencer à classe 1.\n",
    "result = model.predict(image_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cachorro': 0, 'gato': 1}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver os indices da base de dados de treino\n",
    "train_data_base.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função com as classes das imagens\n",
    "\n",
    "# Definiu-se o 0.5 como barreira para pertencer à classe 0 ou classe 1. Esta barreira deve ser modificada quando por exemplo\n",
    "# se trata da administração de medicamentos com efeitos secundários perigosos por exemplo abaixo de 0.99 pertence à classe 0 e\n",
    "# o medicamento não deve ser receitado.\n",
    "\n",
    "def name():\n",
    "    if result < 0.5:\n",
    "        print(\"Cão\")\n",
    "    if result >= 0.5:\n",
    "        print(\"Gato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cão\n"
     ]
    }
   ],
   "source": [
    "# Previsão do objecto na imagem\n",
    "name()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
