{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação Binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação usando uma rede neural artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"personagens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laranja_camisa_bart</th>\n",
       "      <th>azul_calcao_bart</th>\n",
       "      <th>azul_sapato_bart</th>\n",
       "      <th>marrom_boca_homer</th>\n",
       "      <th>azul_calca_homer</th>\n",
       "      <th>cinza_sapato_homer</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.886102</td>\n",
       "      <td>3.495204</td>\n",
       "      <td>1.484984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.004901</td>\n",
       "      <td>3.183889</td>\n",
       "      <td>1.000142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033024</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.264620</td>\n",
       "      <td>5.029683</td>\n",
       "      <td>0.283567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151573</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.978929</td>\n",
       "      <td>3.459119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   laranja_camisa_bart  azul_calcao_bart  azul_sapato_bart  marrom_boca_homer  \\\n",
       "0             6.886102          3.495204          1.484984           0.000000   \n",
       "1             5.004901          3.183889          1.000142           0.000000   \n",
       "2             5.264620          5.029683          0.283567           0.000000   \n",
       "3             0.000000          0.000000          0.000000           0.480168   \n",
       "4             8.978929          3.459119          0.000000           0.000000   \n",
       "\n",
       "   azul_calca_homer  cinza_sapato_homer classe  \n",
       "0               0.0            0.062954   Bart  \n",
       "1               0.0            0.033024   Bart  \n",
       "2               0.0            0.151573   Bart  \n",
       "3               0.0            0.021164   Bart  \n",
       "4               0.0            0.011593   Bart  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação de variaveis categóricas em quantitativas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como é um problema de classificação binária não se pode utilizar as variaveis dummies\n",
    "y_enc = enc.fit_transform(data['classe'])\n",
    "y_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão Treino-Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laranja_camisa_bart</th>\n",
       "      <th>azul_calcao_bart</th>\n",
       "      <th>azul_sapato_bart</th>\n",
       "      <th>marrom_boca_homer</th>\n",
       "      <th>azul_calca_homer</th>\n",
       "      <th>cinza_sapato_homer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.886102</td>\n",
       "      <td>3.495204</td>\n",
       "      <td>1.484984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.004901</td>\n",
       "      <td>3.183889</td>\n",
       "      <td>1.000142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   laranja_camisa_bart  azul_calcao_bart  azul_sapato_bart  marrom_boca_homer  \\\n",
       "0             6.886102          3.495204          1.484984                0.0   \n",
       "1             5.004901          3.183889          1.000142                0.0   \n",
       "\n",
       "   azul_calca_homer  cinza_sapato_homer  \n",
       "0               0.0            0.062954  \n",
       "1               0.0            0.033024  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X - variáveis usadas para modelar o modelo\n",
    "X = data.drop(\"classe\", axis=1)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y - variavel que se pretende avaliar\n",
    "y = y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo da rede neural artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(units=16, activation=\"relu\", kernel_initializer=\"random_uniform\", input_dim=6))\n",
    "model.add(layers.Dense(units=16, activation=\"relu\", kernel_initializer=\"random_uniform\"))\n",
    "model.add(layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilação e Ajuste do modelo ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0705 14:45:06.844087   328 deprecation.py:323] From C:\\Users\\Bruno\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 219 samples\n",
      "Epoch 1/100\n",
      "219/219 [==============================] - 0s 1ms/sample - loss: 0.6790 - binary_accuracy: 0.8174\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 0s 224us/sample - loss: 0.6336 - binary_accuracy: 0.8447\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 0s 187us/sample - loss: 0.5351 - binary_accuracy: 0.8676\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 0s 178us/sample - loss: 0.4109 - binary_accuracy: 0.8904\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 0s 178us/sample - loss: 0.3133 - binary_accuracy: 0.9041\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 0s 197us/sample - loss: 0.2576 - binary_accuracy: 0.9224\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 0s 174us/sample - loss: 0.2268 - binary_accuracy: 0.9224\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 0s 210us/sample - loss: 0.2099 - binary_accuracy: 0.8813\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 0s 196us/sample - loss: 0.1968 - binary_accuracy: 0.9361\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 0s 187us/sample - loss: 0.1890 - binary_accuracy: 0.9132\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 0s 164us/sample - loss: 0.1828 - binary_accuracy: 0.9224\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 0s 178us/sample - loss: 0.1787 - binary_accuracy: 0.8995\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 0s 201us/sample - loss: 0.1738 - binary_accuracy: 0.9269\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 0s 196us/sample - loss: 0.1709 - binary_accuracy: 0.9269\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 0s 228us/sample - loss: 0.1677 - binary_accuracy: 0.9269\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 0s 274us/sample - loss: 0.1657 - binary_accuracy: 0.9269\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 0s 192us/sample - loss: 0.1641 - binary_accuracy: 0.9269\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 0s 183us/sample - loss: 0.1630 - binary_accuracy: 0.9224\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 0s 196us/sample - loss: 0.1611 - binary_accuracy: 0.9269\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 0s 206us/sample - loss: 0.1604 - binary_accuracy: 0.9269\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 0s 210us/sample - loss: 0.1584 - binary_accuracy: 0.9224\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 0s 206us/sample - loss: 0.1572 - binary_accuracy: 0.9178\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 0s 215us/sample - loss: 0.1560 - binary_accuracy: 0.9224\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 0s 183us/sample - loss: 0.1563 - binary_accuracy: 0.9178\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 0s 183us/sample - loss: 0.1540 - binary_accuracy: 0.9269\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 0s 196us/sample - loss: 0.1553 - binary_accuracy: 0.9224\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 0s 206us/sample - loss: 0.1526 - binary_accuracy: 0.9269\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 0s 219us/sample - loss: 0.1520 - binary_accuracy: 0.9224\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 0s 206us/sample - loss: 0.1510 - binary_accuracy: 0.9224\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 0s 201us/sample - loss: 0.1501 - binary_accuracy: 0.9224\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 0s 196us/sample - loss: 0.1497 - binary_accuracy: 0.9269\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 0s 192us/sample - loss: 0.1493 - binary_accuracy: 0.9224\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 0s 201us/sample - loss: 0.1481 - binary_accuracy: 0.9224\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 0s 192us/sample - loss: 0.1482 - binary_accuracy: 0.9269\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 0s 183us/sample - loss: 0.1468 - binary_accuracy: 0.9224\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 0s 183us/sample - loss: 0.1461 - binary_accuracy: 0.9224\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 0s 178us/sample - loss: 0.1480 - binary_accuracy: 0.9224\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 0s 210us/sample - loss: 0.1464 - binary_accuracy: 0.9224\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 0s 228us/sample - loss: 0.1452 - binary_accuracy: 0.9224\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 0s 192us/sample - loss: 0.1447 - binary_accuracy: 0.9224\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 0s 192us/sample - loss: 0.1444 - binary_accuracy: 0.9224\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 0s 187us/sample - loss: 0.1441 - binary_accuracy: 0.9224\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 0s 192us/sample - loss: 0.1438 - binary_accuracy: 0.9224\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 0s 183us/sample - loss: 0.1431 - binary_accuracy: 0.9224\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 0s 192us/sample - loss: 0.1427 - binary_accuracy: 0.9224\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 0s 201us/sample - loss: 0.1441 - binary_accuracy: 0.9224\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 0s 178us/sample - loss: 0.1438 - binary_accuracy: 0.9315\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 0s 196us/sample - loss: 0.1427 - binary_accuracy: 0.9224\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 0s 178us/sample - loss: 0.1414 - binary_accuracy: 0.9224\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 0s 187us/sample - loss: 0.1405 - binary_accuracy: 0.9224\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 0s 183us/sample - loss: 0.1417 - binary_accuracy: 0.9224\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 0s 196us/sample - loss: 0.1412 - binary_accuracy: 0.9269\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 0s 224us/sample - loss: 0.1402 - binary_accuracy: 0.9269\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 0s 215us/sample - loss: 0.1400 - binary_accuracy: 0.9224\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 0s 210us/sample - loss: 0.1393 - binary_accuracy: 0.9269\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 0s 210us/sample - loss: 0.1401 - binary_accuracy: 0.9361\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 0s 187us/sample - loss: 0.1397 - binary_accuracy: 0.9224\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 0s 210us/sample - loss: 0.1401 - binary_accuracy: 0.9224\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 0s 183us/sample - loss: 0.1382 - binary_accuracy: 0.9224\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 0s 206us/sample - loss: 0.1417 - binary_accuracy: 0.9361\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 0s 196us/sample - loss: 0.1370 - binary_accuracy: 0.9406\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 0s 210us/sample - loss: 0.1386 - binary_accuracy: 0.9269\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 0s 196us/sample - loss: 0.1371 - binary_accuracy: 0.9224\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 0s 169us/sample - loss: 0.1371 - binary_accuracy: 0.9224\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 0s 169us/sample - loss: 0.1391 - binary_accuracy: 0.9315\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 0s 165us/sample - loss: 0.1368 - binary_accuracy: 0.9269\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 0s 148us/sample - loss: 0.1363 - binary_accuracy: 0.9224\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 0s 169us/sample - loss: 0.1362 - binary_accuracy: 0.9269\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 0s 165us/sample - loss: 0.1372 - binary_accuracy: 0.9315\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 0s 164us/sample - loss: 0.1367 - binary_accuracy: 0.9224\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 0s 169us/sample - loss: 0.1364 - binary_accuracy: 0.9269\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 0s 187us/sample - loss: 0.1382 - binary_accuracy: 0.9224\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 165us/sample - loss: 0.1352 - binary_accuracy: 0.9315\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 0s 169us/sample - loss: 0.1355 - binary_accuracy: 0.9406\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 0s 189us/sample - loss: 0.1347 - binary_accuracy: 0.9406\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 0s 174us/sample - loss: 0.1343 - binary_accuracy: 0.9315\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 0s 160us/sample - loss: 0.1360 - binary_accuracy: 0.9406\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 0s 150us/sample - loss: 0.1347 - binary_accuracy: 0.9269\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 0s 166us/sample - loss: 0.1355 - binary_accuracy: 0.9269\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 0s 170us/sample - loss: 0.1350 - binary_accuracy: 0.9406\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 0s 160us/sample - loss: 0.1343 - binary_accuracy: 0.9406\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 0s 174us/sample - loss: 0.1335 - binary_accuracy: 0.9269\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 0s 165us/sample - loss: 0.1329 - binary_accuracy: 0.9406\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 0s 142us/sample - loss: 0.1331 - binary_accuracy: 0.9406\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 0s 187us/sample - loss: 0.1337 - binary_accuracy: 0.9406\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 0s 192us/sample - loss: 0.1324 - binary_accuracy: 0.9361\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 0s 164us/sample - loss: 0.1335 - binary_accuracy: 0.9406\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 0s 169us/sample - loss: 0.1349 - binary_accuracy: 0.9315\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 0s 210us/sample - loss: 0.1333 - binary_accuracy: 0.9406\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 0s 192us/sample - loss: 0.1342 - binary_accuracy: 0.9361\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 0s 165us/sample - loss: 0.1321 - binary_accuracy: 0.9315\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 0s 155us/sample - loss: 0.1321 - binary_accuracy: 0.9406\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 0s 187us/sample - loss: 0.1319 - binary_accuracy: 0.9406\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 0s 160us/sample - loss: 0.1338 - binary_accuracy: 0.9315\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 0s 155us/sample - loss: 0.1311 - binary_accuracy: 0.9315\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 0s 187us/sample - loss: 0.1309 - binary_accuracy: 0.9406\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 0s 169us/sample - loss: 0.1315 - binary_accuracy: 0.9406\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 0s 169us/sample - loss: 0.1307 - binary_accuracy: 0.9406\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 0s 152us/sample - loss: 0.1309 - binary_accuracy: 0.9406\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 0s 176us/sample - loss: 0.1316 - binary_accuracy: 0.9406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x83b6a74c50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar os dados de entrada de treino aos dados de saida de treino para treinar o modelo\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 832us/sample - loss: 0.2178 - binary_accuracy: 0.8784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21780325351534663, 0.8783784]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliação do modelo ANN para os dados de teste com o TensorFlow 2.0\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação usando uma rede neural convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augumentation - Alteração das caracteristicas das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tem-se 196 imagens para traino e 73 imagens para teste. É uma quantidade pequena de imagens. Utiliza-se o Augmentation para o \n",
    "# treino ser feito\n",
    "# em cada epoca com imagens diferentes das originais. Deste modo apesar de o treino ser feito com a mesma quantidade de imagens\n",
    "# (196) em cada epoca é utilizada uma versão diferente dessas imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações nas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_base_generator = preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=7, horizontal_flip=True, \n",
    "                                                                   shear_range=0.2, height_shift_range=0.07, zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como não se utilizaram parâmetros não faz alterações na imagem. Mantem as imagens originais.\n",
    "# Como as imagens de treino devem ser diferentes das imagens de teste(apenas devem ter a mesma escala) não é necessário fazer \n",
    "# alterações na base de dados de teste.\n",
    "test_data_base_generator = preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar nova base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 196 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Existem imagens com dimensões diferentes. Optou-se por utilizar a dimensão 64x64 pixeis para todas as imagens (todas as \n",
    "# imagens têm de ter as mesmas dimensões para a rede neural aplicar os calculos matemáticos).\n",
    "\n",
    "train_data_base = train_data_base_generator.flow_from_directory(\"dataset_personagens/training_set\",target_size=(64,64), \n",
    "                                                                batch_size=10, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 73 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_base = test_data_base_generator.flow_from_directory(\"dataset_personagens/test_set\",target_size=(64,64), batch_size=10,\n",
    "                                                               class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo da rede neural convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectores de caracteristicas:32\n",
    "# Kernel_size: (3,3) matriz detectora de caracteristicas do tamanho 3x3 \n",
    "# input_shape: dimensões da imagem e número de canais(3 para imagens com cor). \n",
    "\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Conv2D(32, (3,3), input_shape=(64, 64, 3), activation=\"relu\")) \n",
    "model1.add(layers.BatchNormalization())                                          \n",
    "model1.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(layers.Conv2D(32, (3,3), activation=\"relu\")) \n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model1.add(layers.Flatten()) \n",
    "\n",
    "model1.add(layers.Dense(units=128, activation=\"relu\")) \n",
    "model1.add(layers.Dropout(0.2))\n",
    "\n",
    "model1.add(layers.Dense(units=1, activation=\"sigmoid\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilação e Ajuste do modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "model1.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 15s 537ms/step - loss: 0.0638 - accuracy: 0.9847 - val_loss: 0.8406 - val_accuracy: 0.7668\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 15s 524ms/step - loss: 0.2029 - accuracy: 0.9452 - val_loss: 2.0562 - val_accuracy: 0.6254\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 15s 527ms/step - loss: 0.1011 - accuracy: 0.9566 - val_loss: 1.8355 - val_accuracy: 0.6219\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 15s 526ms/step - loss: 0.0726 - accuracy: 0.9796 - val_loss: 0.8413 - val_accuracy: 0.7385\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 15s 527ms/step - loss: 0.0517 - accuracy: 0.9834 - val_loss: 0.5860 - val_accuracy: 0.8587\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 15s 531ms/step - loss: 0.0559 - accuracy: 0.9821 - val_loss: 0.2228 - val_accuracy: 0.9046\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 15s 524ms/step - loss: 0.0246 - accuracy: 0.9949 - val_loss: 0.3012 - val_accuracy: 0.8905\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 15s 518ms/step - loss: 0.0432 - accuracy: 0.9885 - val_loss: 0.3880 - val_accuracy: 0.8975\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 15s 523ms/step - loss: 0.0759 - accuracy: 0.9770 - val_loss: 0.4535 - val_accuracy: 0.8693\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 15s 536ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.3705 - val_accuracy: 0.8940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x83bdcb26a0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar os dados de entrada de treino aos dados de saida para treinar o modelo(Estão os dois na base de dados de treino).\n",
    "model1.fit_generator(train_data_base, steps_per_epoch=196/7, epochs=10, validation_data=test_data_base, \n",
    "                    validation_steps=73/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3278 - accuracy: 0.8904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3277823527654012, 0.89041096]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliação do modelo CNN para os dados de teste com o TensorFlow 2.0\n",
    "model1.evaluate(test_data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
