{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural Recorrente - Série Temporal com vários previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obter os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"petr4-treinamento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>20.209999</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>18.086271</td>\n",
       "      <td>30182600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>19.809999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>18.738441</td>\n",
       "      <td>30552600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>20.170000</td>\n",
       "      <td>20.430000</td>\n",
       "      <td>18.766001</td>\n",
       "      <td>36141000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>20.080000</td>\n",
       "      <td>18.444506</td>\n",
       "      <td>28069600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.230000</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>17.911745</td>\n",
       "      <td>29091300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       "1  2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       "2  2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       "3  2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
       "4  2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
       "\n",
       "       Volume  \n",
       "0  30182600.0  \n",
       "1  30552600.0  \n",
       "2  36141000.0  \n",
       "3  28069600.0  \n",
       "4  29091300.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos dados de treino - Apagar dados Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         3\n",
       "High         3\n",
       "Low          3\n",
       "Close        3\n",
       "Adj Close    3\n",
       "Volume       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Só existem valores ausentes nos dados de treino\n",
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1245, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamanho original do dataset de treino\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como apenas 3 linhas têm valores ausentes optou-se por apagar essas linhas.\n",
    "data_train = data_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirmação de ter-se removido apenas 3 linhas\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirmação da anão existencia de valores nulos\n",
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos dados de treino- Normalização das Variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizar as variaveis\n",
    "# Vão-se mormalizar todas as variaveis menos a data porque vão ser utilizadas para fazer o treino do modelo.\n",
    "scaler.fit(data_train.drop([\"Date\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array com as variaveis normalizadas\n",
    "open_norm_train = scaler.fit_transform(data_train.drop([\"Date\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_norm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76501938, 0.7562984 , 0.78149225, ..., 0.57122093, 0.57655039,\n",
       "       0.57655039])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_norm_train[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizar todas as variaveis para prever o preço de abertura das acções.\n",
    "open_norm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prever o preço das acções com base nos preços de abertura nos 90 dias anteriores.\n",
    "\n",
    "X_train = [] # vector com os preços e volume nos 90 dias anteriores.\n",
    "y_train = [] # vector com o preço de abertura da acção no dia 91."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Só é possivel prever o preço das acções desde o dia 90 até ao dia 1242. Porque só se tem registro de 1242 dias e \n",
    "# estabeleceu-se como critério utilizar os 90 dias anteriores para fazer uma previsão.\n",
    "\n",
    "for i in range(90, 1242):\n",
    "    X_train.append(open_norm_train[i-90:i,0:6]) # valores dos preços e volume\n",
    "    y_train.append(open_norm_train[i, 0]) # valor do preço de abertura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter os vectores(listas) em arrays\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 90, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1152 registros com os 90 dias anteriores para as 6 variaveis utilizadas para fazer a previsão.\n",
    "# Para prever o preço nestes 1152 dias utilizam-se os 90 dias anteriores a cada dia a prever.\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76501938, 0.7562984 , 0.78149225, 0.78875969, 0.77083338,\n",
       "       0.74806197, 0.75436047, 0.75823643, 0.76598837, 0.76598837,\n",
       "       0.76017437, 0.75872098, 0.75581391, 0.74467054, 0.7374031 ,\n",
       "       0.7374031 , 0.73498067, 0.75242248, 0.73401163, 0.71656977,\n",
       "       0.68120155, 0.67538755, 0.67635659, 0.63372098, 0.66521318,\n",
       "       0.65649225, 0.64680228, 0.66618222, 0.65843028, 0.64970935,\n",
       "       0.65116274, 0.66424419, 0.67344961, 0.64292631, 0.64486434,\n",
       "       0.62257747, 0.60949617, 0.60998067, 0.60852713, 0.59593023,\n",
       "       0.61143411, 0.60222863, 0.64922481, 0.68362398, 0.70687989,\n",
       "       0.68265509, 0.70978682, 0.70784879, 0.71608527, 0.73643411,\n",
       "       0.7122093 , 0.7122093 , 0.7194767 , 0.70348832, 0.69525189,\n",
       "       0.70397287, 0.70397287, 0.69767442, 0.68168605, 0.68168605,\n",
       "       0.65310078, 0.66618222, 0.64825581, 0.66182175, 0.64341085,\n",
       "       0.67877902, 0.69137592, 0.66569772, 0.65406982, 0.64292631,\n",
       "       0.64147292, 0.63565891, 0.67587209, 0.68653106, 0.70300383,\n",
       "       0.71996119, 0.73982553, 0.76550388, 0.74854651, 0.75823643,\n",
       "       0.78924419, 0.76598837, 0.78488372, 0.80184109, 0.77761628,\n",
       "       0.77325581, 0.7562984 , 0.74273261, 0.74127907, 0.74224806])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train[0,:,0]: preços de abertura nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_train[0,:,1]: preços de máximo nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_train[0,:,2]: preços de minimo nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_train[0,:,3]: preços de fecho nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_train[0,:,4]: preços de fecho ajustado nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_train[0,:,5]: volume transaccionado nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_train[1,:,5]: volume transaccionado entre o dia 1 e 91. Utilizado para prever o preço de abertura no dia 92.\n",
    "\n",
    "X_train[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76114341])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train[0:1]: preço de abertura (normalizado) no dia 91.\n",
    "# y_train[1:2] preço de abertura (normalizado) no dia 92.\n",
    "y_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A camada de entrada tem de ser um tensor 3d (input_shape, timesteps, input_dim)\n",
    "# input_shape: 1152 registros. Número de registros totais\n",
    "# timesteps: 90 registros. Número de registros utilizados para fazer a previsão.\n",
    "#input_dim: 6 indicador(6 variaveis de entrada utilizadas para fazer a previsão).\n",
    "\n",
    "# Não é necessário porque o array já está no formato correcto\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Rede Neural Recorrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential - A informação é passada de uma camada para a camada seguinte\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada LSTM\n",
    "\n",
    "# LSTM - Long short term memory. AS redes neurais simples têm dificuldade em \"aprender\" alguns tipos de padrões mais complexos.\n",
    "# Nesses casos pode-se utilizar o tipo de rede neural recorrente LSTM que aprende \"dependencias\" de longo prazo.\n",
    "\n",
    "# As redes neurais recorrentes simples armazenam as informações no tempo atraves de loops( o neuronio apenas aponta para ele \n",
    "# mesmo e para a camada seguinte). Isto permte que a informação persista.\n",
    "# As redes neurais recorrentes LSTM para alem disso têm celulas de memoria e manipulam essas celulas de modo a filtrar e \n",
    "# armazenar a informação importante nessas celulas.\n",
    "\n",
    "# As redes neurais recorrentes ajudam no problema do gradiente desaparecendo(vanish gradient). No ajuste dos pesos ao se\n",
    "# utilizar a descida do gradiente e a sua actualização atraves de backpropagation em primeiro faz-se os calculos da camada\n",
    "# de entrada para a camada de saida. Os pesos são depois actalizados a partir da camada de saida para a camada de entrada. Os\n",
    "# pesos vão sendo actualizados utilizando o learning rate(maiores alterações nas 1ªs camadas). Caso se tenha muitos loops\n",
    "# as ultimas actualizações do gradiente são muito pequenas, o que faz com que o peso não tenha alteração no seu valor.\n",
    "\n",
    "# Número de celulas de memoria(units): Número de vezes(loops) em que a informação é passada ao mesmo neuronio e a camada \n",
    "# seguinte (numero de cópias da camada). Deve ser um valor alto para adicinonar mais dimensionalidade e decorar a tendencia ao \n",
    "# longo do tempo.\n",
    "\n",
    "# Return_sequence: True. Apenas se utilizada quando se tem mais de uma camada LSTM. Indica que a informação será passada para a\n",
    "# camada seguinte.\n",
    "\n",
    "# input_shape: Número de registros utilizados para fazer a previsão(90) e número de variaveis de entrada(6).\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# Camada densa\n",
    "\n",
    "# Todos os neuronios da ultima camada( segunda camada LSTM) estão conectados à camada de saida. Nas camadas LSTM isso tambem\n",
    "# acontece.\n",
    "\n",
    "# units: 1. Só se quer prever o valor Open.\n",
    "# activation: linear. É um problema de regressão. Como os valores estão normalizados(entre 0 e 1) caso se utiliza-se a função\n",
    "# sigmoid tambem se retornaria valores entre 0 e 1.\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], 6)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.LSTM(units=50, return_sequences=True))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.LSTM(units=50, return_sequences=True))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.LSTM(units=50))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilação e Ajuste do modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer: pode-se utilizar o RMSprop, indicado para redes neurais recorrentes, ou o adam que obtem resultados semelhantes.\n",
    "# loss: mean_squared_error é o parametro utilizado para problemas de regressão.\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks: contem um conjunto de funções que podem ser aplicadas durante o treino. São usadas para se ter uma visão das fases\n",
    "# internas e estatisticas do modelo.\n",
    "\n",
    "# EarlyStopping: Pára o treino se uma quantidade definida parar de melhorar.Por exemplo se durante 30 épocas o valor da loss \n",
    "\n",
    "# function não melhorar, o treino é parado.\n",
    "# monitor: função a avaliar\n",
    "# min_delta: valor minimo definido da function para se continuar o treino. Se esse valor não for atingido durante \"patiente\" \n",
    "# épocas o treino pára.\n",
    "# patience: número de epocas em que a função não melhorar. Se durante estas epocas a função não melhorar o treino pára.\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor=\"loss\", min_delta=1e-10, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau(): Reduz a taxa de aprendizagem quando uma função pára de melhorar.\n",
    "# Se a loss function não melhorar depois de, por exemplo 2 ou 3 epocas, reduz a taxa de aprendizagem para melhorar o valor da\n",
    "# função.\n",
    "\n",
    "# factor: factor pelo qual a learning rateé reduzida, factorxlr()\n",
    "# min_delta: \n",
    "\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=\"loss\", patience=5, factor=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráva o modelo no fim de cada época\n",
    "\n",
    "# monitor: função a avaliar\n",
    "# save_best_only: grava apenas o modelo com o melhor resultado\n",
    "\n",
    "ncp = callbacks.ModelCheckpoint(monitor=\"loss\", save_best_only=True, filepath=\"pesos.h5\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1152 samples\n",
      "Epoch 1/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0193 - mean_absolute_error: 0.1054\n",
      "Epoch 00001: loss improved from inf to 0.01891, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 11s 9ms/sample - loss: 0.0189 - mean_absolute_error: 0.1042\n",
      "Epoch 2/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0053 - mean_absolute_error: 0.0580\n",
      "Epoch 00002: loss improved from 0.01891 to 0.00526, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0053 - mean_absolute_error: 0.0575\n",
      "Epoch 3/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0496\n",
      "Epoch 00003: loss improved from 0.00526 to 0.00404, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0040 - mean_absolute_error: 0.0497\n",
      "Epoch 4/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0507\n",
      "Epoch 00004: loss did not improve from 0.00404\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.0042 - mean_absolute_error: 0.0507\n",
      "Epoch 5/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0476\n",
      "Epoch 00005: loss improved from 0.00404 to 0.00379, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0038 - mean_absolute_error: 0.0475\n",
      "Epoch 6/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0467\n",
      "Epoch 00006: loss improved from 0.00379 to 0.00366, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0037 - mean_absolute_error: 0.0464\n",
      "Epoch 7/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0430\n",
      "Epoch 00007: loss improved from 0.00366 to 0.00309, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0031 - mean_absolute_error: 0.0428\n",
      "Epoch 8/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0424\n",
      "Epoch 00008: loss improved from 0.00309 to 0.00303, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0030 - mean_absolute_error: 0.0423\n",
      "Epoch 9/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0439\n",
      "Epoch 00009: loss did not improve from 0.00303\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0032 - mean_absolute_error: 0.0436\n",
      "Epoch 10/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0415\n",
      "Epoch 00010: loss improved from 0.00303 to 0.00295, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0029 - mean_absolute_error: 0.0412\n",
      "Epoch 11/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0389\n",
      "Epoch 00011: loss improved from 0.00295 to 0.00253, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0025 - mean_absolute_error: 0.0387\n",
      "Epoch 12/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0366\n",
      "Epoch 00012: loss improved from 0.00253 to 0.00229, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0023 - mean_absolute_error: 0.0365\n",
      "Epoch 13/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0397\n",
      "Epoch 00013: loss did not improve from 0.00229\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.0026 - mean_absolute_error: 0.0395\n",
      "Epoch 14/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0365\n",
      "Epoch 00014: loss improved from 0.00229 to 0.00225, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0022 - mean_absolute_error: 0.0364\n",
      "Epoch 15/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0355\n",
      "Epoch 00015: loss improved from 0.00225 to 0.00217, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0022 - mean_absolute_error: 0.0356\n",
      "Epoch 16/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0357\n",
      "Epoch 00016: loss improved from 0.00217 to 0.00213, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0021 - mean_absolute_error: 0.0356\n",
      "Epoch 17/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0330\n",
      "Epoch 00017: loss improved from 0.00213 to 0.00187, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.0019 - mean_absolute_error: 0.0333\n",
      "Epoch 18/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0345\n",
      "Epoch 00018: loss did not improve from 0.00187\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.0020 - mean_absolute_error: 0.0343\n",
      "Epoch 19/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0335\n",
      "Epoch 00019: loss did not improve from 0.00187\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0019 - mean_absolute_error: 0.0336\n",
      "Epoch 20/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0336\n",
      "Epoch 00020: loss did not improve from 0.00187\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0019 - mean_absolute_error: 0.0334\n",
      "Epoch 21/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0322\n",
      "Epoch 00021: loss improved from 0.00187 to 0.00181, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.0018 - mean_absolute_error: 0.0322\n",
      "Epoch 22/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0319\n",
      "Epoch 00022: loss improved from 0.00181 to 0.00176, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.0018 - mean_absolute_error: 0.0321\n",
      "Epoch 23/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0312\n",
      "Epoch 00023: loss improved from 0.00176 to 0.00170, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0017 - mean_absolute_error: 0.0312\n",
      "Epoch 24/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0307\n",
      "Epoch 00024: loss improved from 0.00170 to 0.00163, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0016 - mean_absolute_error: 0.0307\n",
      "Epoch 25/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0290\n",
      "Epoch 00025: loss improved from 0.00163 to 0.00150, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0015 - mean_absolute_error: 0.0288\n",
      "Epoch 26/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0305\n",
      "Epoch 00026: loss did not improve from 0.00150\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0016 - mean_absolute_error: 0.0305\n",
      "Epoch 27/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0312\n",
      "Epoch 00027: loss did not improve from 0.00150\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0017 - mean_absolute_error: 0.0313\n",
      "Epoch 28/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0325\n",
      "Epoch 00028: loss did not improve from 0.00150\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0018 - mean_absolute_error: 0.0324\n",
      "Epoch 29/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0280\n",
      "Epoch 00029: loss improved from 0.00150 to 0.00140, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0014 - mean_absolute_error: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0297\n",
      "Epoch 00030: loss did not improve from 0.00140\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0015 - mean_absolute_error: 0.0298\n",
      "Epoch 31/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0286\n",
      "Epoch 00031: loss did not improve from 0.00140\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0014 - mean_absolute_error: 0.0285\n",
      "Epoch 32/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0276\n",
      "Epoch 00032: loss improved from 0.00140 to 0.00136, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0014 - mean_absolute_error: 0.0278\n",
      "Epoch 33/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0282\n",
      "Epoch 00033: loss did not improve from 0.00136\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0014 - mean_absolute_error: 0.0281\n",
      "Epoch 34/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0286\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00136\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0015 - mean_absolute_error: 0.0287\n",
      "Epoch 35/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0275\n",
      "Epoch 00035: loss did not improve from 0.00136\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0014 - mean_absolute_error: 0.0276\n",
      "Epoch 36/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0262\n",
      "Epoch 00036: loss improved from 0.00136 to 0.00124, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0012 - mean_absolute_error: 0.0262\n",
      "Epoch 37/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0266\n",
      "Epoch 00037: loss improved from 0.00124 to 0.00122, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0012 - mean_absolute_error: 0.0265\n",
      "Epoch 38/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0269\n",
      "Epoch 00038: loss did not improve from 0.00122\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0013 - mean_absolute_error: 0.0270\n",
      "Epoch 39/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0248\n",
      "Epoch 00039: loss improved from 0.00122 to 0.00115, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0011 - mean_absolute_error: 0.0249\n",
      "Epoch 40/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0255\n",
      "Epoch 00040: loss did not improve from 0.00115\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0012 - mean_absolute_error: 0.0254\n",
      "Epoch 41/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0256\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00115\n",
      "1152/1152 [==============================] - 8s 7ms/sample - loss: 0.0012 - mean_absolute_error: 0.0255\n",
      "Epoch 42/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0251\n",
      "Epoch 00042: loss did not improve from 0.00115\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0012 - mean_absolute_error: 0.0251\n",
      "Epoch 43/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0254\n",
      "Epoch 00043: loss did not improve from 0.00115\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0011 - mean_absolute_error: 0.0252\n",
      "Epoch 44/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0253\n",
      "Epoch 00044: loss did not improve from 0.00115\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0012 - mean_absolute_error: 0.0252\n",
      "Epoch 45/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0246\n",
      "Epoch 00045: loss improved from 0.00115 to 0.00109, saving model to pesos.h5\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0011 - mean_absolute_error: 0.0245\n",
      "Epoch 46/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0248\n",
      "Epoch 00046: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0011 - mean_absolute_error: 0.0248\n",
      "Epoch 47/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0251\n",
      "Epoch 00047: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0011 - mean_absolute_error: 0.0251\n",
      "Epoch 48/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0250\n",
      "Epoch 00048: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0012 - mean_absolute_error: 0.0250\n",
      "Epoch 49/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0255\n",
      "Epoch 00049: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0012 - mean_absolute_error: 0.0255\n",
      "Epoch 50/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0246\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0011 - mean_absolute_error: 0.0247\n",
      "Epoch 51/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0247\n",
      "Epoch 00051: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0011 - mean_absolute_error: 0.0246\n",
      "Epoch 52/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0253\n",
      "Epoch 00052: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0012 - mean_absolute_error: 0.0253\n",
      "Epoch 53/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0254\n",
      "Epoch 00053: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 7ms/sample - loss: 0.0012 - mean_absolute_error: 0.0252\n",
      "Epoch 54/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0252\n",
      "Epoch 00054: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0012 - mean_absolute_error: 0.0252\n",
      "Epoch 55/100\n",
      "1120/1152 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0254\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.00109\n",
      "1152/1152 [==============================] - 9s 8ms/sample - loss: 0.0011 - mean_absolute_error: 0.0253\n",
      "Epoch 00055: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xbe4ccde7f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar os dados de entrada de treino aos dados de saida para treinar o modelo.\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, callbacks=[es, rlr, ncp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obter os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"petr4-teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.516966</td>\n",
       "      <td>33461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>16.490000</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>55940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16.780001</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>16.620001</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>16.696608</td>\n",
       "      <td>37064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>16.570000</td>\n",
       "      <td>16.830000</td>\n",
       "      <td>16.796408</td>\n",
       "      <td>26958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>16.740000</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.709999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.996010</td>\n",
       "      <td>28400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966  33461800\n",
       "1  2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668  55940900\n",
       "2  2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608  37064900\n",
       "3  2018-01-05  16.700001  16.860001  16.570000  16.830000  16.796408  26958200\n",
       "4  2018-01-08  16.740000  17.030001  16.709999  17.030001  16.996010  28400000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista com os dados totais\n",
    "data_total = [data_train, data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a lista data_total em dataframe\n",
    "data_total = pd.concat(data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1264, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_train tem os dados desde 2013-01-02 até 2017-12-29\n",
    "# data_teste tem os dados desde 2018-01-02 até 2018-01-31\n",
    "# data tem dos dados desde 2013-01-02 até 2018-01-31\n",
    "\n",
    "# 1242+22 = 1264 registros com 7 variaveis\n",
    "data_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirar a variavel date que não é utilizada para fazer previsões\n",
    "data_total = data_total.drop(\"Date\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados desde 2017-08-28 até 2018-01-31\n",
    "data_total_test = data_total[len(data_total) - len(data_test)-90:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 22+90=112 dias de preços e volume\n",
    "# O X_test contem os 22 dias da base de dados de teste mais os 90 dias anteriores. Esses 90 dias anteriores são necessários \n",
    "# para se poderem fazer previssões.\n",
    "data_total_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.76"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total_test[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos dados de teste - Normalização das Variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar as variaveis de entrada\n",
    "# Não é necessário fazer o fit porque já foi feito anteriormente no treino.\n",
    "data_total_test_norm =scaler.transform(data_total_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46317829, 0.46463178, 0.45203488, 0.46753876])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variavel Open normalizada com o scaler\n",
    "data_total_test_norm[1:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O array predictions é tem a dimensão (112,1). Quando se inverter a normalização tem de se utilizar um normalizador que esteja\n",
    "# ajustado por essa dimensão.\n",
    "# O scaler está ajustado para a dimensão (112,6) por isso não pode ser utilizado para reverter a normalização do array \n",
    "# predictions.\n",
    "\n",
    "scaler_prediction = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar e normalizar a variavel Open\n",
    "# Tem de se utilizar a mesma base de dados de treino para que a escala seja a mesma.\n",
    "\n",
    "pred = scaler_prediction.fit_transform(data_train.drop([\"Date\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46317829],\n",
       "       [0.46463178],\n",
       "       [0.45203488],\n",
       "       [0.46753876]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A variavel Open normalizada é igual fazendo a normalização com o scaler ou com o scaler_prediction.\n",
    "pred[1153:1157]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão dos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prever o preço de abertura das acções com base nos preços de abertura nos 90 dias anteriores.\n",
    "\n",
    "X_test = [] # vector com os preços e volume nos 90 dias anteriores.\n",
    "y_test = [] # vector com o preço de abertura da acção no dia 91."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(90, 112):\n",
    "    X_test.append(data_total_test_norm[i-90:i, 0:6]) # valores dos preços e volume\n",
    "    y_test.append(data_total_test_norm[i,0]) # valor do preço de abertura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter as listas em arrays\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 90, 6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 22 registros com os 90 dias anteriores para as 6 variaveis utilizadas para fazer a previsão.\n",
    "# Para prever o preço nestes 22 dias utilizam-se os 90 dias anteriores a cada dia a prever.\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47141473, 0.46317829, 0.46463178, 0.45203488, 0.46753876,\n",
       "       0.47286822, 0.50242248, 0.50629845, 0.52422481, 0.52810078,\n",
       "       0.51744186, 0.52228682, 0.52034884, 0.5247093 , 0.52664729,\n",
       "       0.52422481, 0.52810078, 0.53536822, 0.56443798, 0.55232558,\n",
       "       0.56153101, 0.56492248, 0.55717054, 0.54118217, 0.54748062,\n",
       "       0.53246124, 0.55232558, 0.56686047, 0.56589147, 0.55523256,\n",
       "       0.55281008, 0.57800383, 0.57994186, 0.5755814 , 0.58284884,\n",
       "       0.57945736, 0.57848832, 0.58236429, 0.57170543, 0.5809109 ,\n",
       "       0.58575586, 0.58575586, 0.59738377, 0.60949617, 0.60901163,\n",
       "       0.6187015 , 0.61531008, 0.61967054, 0.61531008, 0.61821701,\n",
       "       0.62257747, 0.63517437, 0.60513571, 0.61482553, 0.6061046 ,\n",
       "       0.60513571, 0.60271313, 0.54021318, 0.55329457, 0.56782946,\n",
       "       0.57267442, 0.57897287, 0.57606589, 0.57073643, 0.58381783,\n",
       "       0.57218992, 0.56831395, 0.56540698, 0.5377907 , 0.53972868,\n",
       "       0.55474806, 0.54748062, 0.53391473, 0.5377907 , 0.54796512,\n",
       "       0.54651163, 0.54069767, 0.55474806, 0.52810078, 0.52567829,\n",
       "       0.53100775, 0.53197674, 0.53343023, 0.53827519, 0.55959302,\n",
       "       0.55959302, 0.55959302, 0.57122093, 0.57655039, 0.57655039])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test[0,:,0]: preços de abertura nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_test[0,:,1]: preços de máximo nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_test[0,:,2]: preços de minimo nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_test[0,:,3]: preços de fecho nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_test[0,:,4]: preços de fecho ajustado nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_test[0,:,5]: volume transaccionado nos primeiros 90 dias. Utilizado para prever o preço de abertura no dia 91.\n",
    "# X_test[1,:,5]: volume transaccionado entre o dia 1 e 91. Utilizado para prever o preço de abertura no dia 92.\n",
    "\n",
    "X_test[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5809109])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test[0:1]: preço de abertura (normalizado) no dia 91.\n",
    "# y_test[1:2] preço de abertura (normalizado) no dia 92.\n",
    "y_test[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A camada de entrada tem de ser um tensor 3d (input_shape, timesteps, input_dim)\n",
    "# input_shape: 22 registros. Número de registros totais de teste\n",
    "# timesteps: 90 registros. Número de registros utilizados para fazer a previsão.\n",
    "#input_dim: 6 indicador(apenas 6 variavel de entrada)\n",
    "\n",
    "# Não é necessário porque o array já está no formato correcto\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão e Avaliação do Modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prever os dados de teste para avaliar o modelo\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverter a normalização do X_test para comparar os valores das acções\n",
    "predictions = scaler_prediction.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverter a normalização do y_test para comparar os valores das acções\n",
    "y_test = scaler_prediction.inverse_transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.130117</td>\n",
       "      <td>16.190001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.215849</td>\n",
       "      <td>16.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.376980</td>\n",
       "      <td>16.780001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.598076</td>\n",
       "      <td>16.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.802332</td>\n",
       "      <td>16.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictions     y_test\n",
       "0    16.130117  16.190001\n",
       "1    16.215849  16.490000\n",
       "2    16.376980  16.780001\n",
       "3    16.598076  16.700001\n",
       "4    16.802332  16.740000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Predictions\": predictions[:,0], \"y_test\":y_test[:,0]}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.2603642565252136\n",
      "MSE 0.13638905150793906\n",
      "RMSE 0.36930888360278996\n"
     ]
    }
   ],
   "source": [
    "# O MSE é muito mais elevado porque penaliza os desvios grandes(são elevados ao quadrado).\n",
    "# O MAE de 0.36 significa que o preço das acções varia +- 0.36 reais. \n",
    "print(\"MAE\", metrics.mean_absolute_error(y_test, predictions))\n",
    "print(\"MSE\", metrics.mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE\", np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.658825"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.874545636363635"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[\"Open\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resíduos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'y_test-predictions')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograma de Residuos \n",
    "# O gráfico não parece aproximar-se de uma distriuição normal, onde os residuos são proximos de zero.\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.distplot(y_test-predictions)\n",
    "plt.xlabel(\"y_test-predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico preço real vs preço previsto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(predictions, color=\"red\", label=\"preço previsto\")\n",
    "plt.plot(y_test, color=\"blue\", label=\"preço real\")\n",
    "plt.title(\"Preço das acções\")\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Preço\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
